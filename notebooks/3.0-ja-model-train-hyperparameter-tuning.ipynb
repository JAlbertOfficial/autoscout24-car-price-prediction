{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, HuberRegressor, QuantileRegressor, RANSACRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\")\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train linear regression model and measure computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression() \n",
    "lr_start = datetime.now()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_stop = datetime.now()\n",
    "lr_delta = lr_stop - lr_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the log-transformation applied to the target variable y_train during data preprocessing to ensure normality and linearity, it is necessary to reverse this transformation on the predictions before assessing the model using metrics such as RMSE and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in expm1\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_test_log = np.log1p(y_test.to_numpy())\n",
    "\n",
    "lr_pred_df = pd.DataFrame({'pred': lr_pred.flatten(), 'y_test': y_test_log.flatten()})\n",
    "\n",
    "lr_pred_df['pred'] = np.expm1(lr_pred_df['pred'])\n",
    "lr_pred_df['y_test'] = np.expm1(lr_pred_df['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the back-transformation, NaNs and Infs occurred for some rows. These entries are eliminated, and the indices of the removed rows are stored to identify the observations that led to these issues. Additionally, the total count and the relative proportion of dropped rows are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before removing NaNs and Infs: 9215\n",
      "Rows after removing NaNs and Infs: 9193\n",
      "Number of rows removed: 22\n",
      "Percentage of rows removed: 0.23874118285404233 %\n",
      "Problematic rows in X_test and y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mileage</th>\n",
       "      <th>offerType</th>\n",
       "      <th>hp</th>\n",
       "      <th>year</th>\n",
       "      <th>make_Audi</th>\n",
       "      <th>make_BMW</th>\n",
       "      <th>make_Bentley</th>\n",
       "      <th>make_Corvette</th>\n",
       "      <th>make_DS</th>\n",
       "      <th>make_Fiat</th>\n",
       "      <th>...</th>\n",
       "      <th>model_S7</th>\n",
       "      <th>model_SLC 250</th>\n",
       "      <th>model_T5 Shuttle</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_Electric</th>\n",
       "      <th>fuel_Gasoline</th>\n",
       "      <th>gear_Automatic</th>\n",
       "      <th>gear_Manual</th>\n",
       "      <th>price</th>\n",
       "      <th>pre_backtrans_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.139248</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83870</td>\n",
       "      <td>3.996071e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34950</td>\n",
       "      <td>5.998644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.339380</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8500</td>\n",
       "      <td>7.560187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.283372</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.678830</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>0.403326</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.810958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99800</td>\n",
       "      <td>3.948626e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>0.126833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.770530</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86885</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0.554074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.493344</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9985</td>\n",
       "      <td>5.998644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>0.398366</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39925</td>\n",
       "      <td>7.201592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>0.208001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45555</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.409779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33994</td>\n",
       "      <td>7.184330e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>0.377976</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29950</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.854646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175470</td>\n",
       "      <td>3.131556e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>0.200830</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52490</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>0.608220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.448622</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17300</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>0.449051</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.373640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1190</td>\n",
       "      <td>1.721461e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>0.332922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.398820</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9900</td>\n",
       "      <td>1.609189e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748</th>\n",
       "      <td>0.442519</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.361263</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7480</td>\n",
       "      <td>7.560187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>0.445133</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.520298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10900</td>\n",
       "      <td>6.466283e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8357</th>\n",
       "      <td>0.244699</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.886967</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94900</td>\n",
       "      <td>1.463901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8424</th>\n",
       "      <td>0.374173</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.766887</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44930</td>\n",
       "      <td>7.201592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>0.483186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.327765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3400</td>\n",
       "      <td>6.316963e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>0.075173</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.305522</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55900</td>\n",
       "      <td>3.722491e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mileage  offerType        hp  year  make_Audi  make_BMW  make_Bentley  \\\n",
       "77    0.139248       0.50  0.538058   1.0          0         0             0   \n",
       "101   0.300000       0.00  0.732819   0.6          0         0             0   \n",
       "824   0.406800       0.00  0.339380   0.5          0         0             0   \n",
       "1032  0.283372       0.00  0.678830   0.7          0         1             0   \n",
       "2314  0.403326       0.00  0.810958   0.0          0         0             1   \n",
       "2468  0.126833       0.00  0.770530   0.8          0         0             0   \n",
       "2550  0.554074       0.00  0.493344   0.4          0         0             0   \n",
       "3623  0.398366       0.00  0.744444   0.3          1         0             0   \n",
       "3684  0.208001       0.50  0.538058   1.0          0         0             0   \n",
       "4405  0.020801       0.75  0.409779   1.0          0         0             0   \n",
       "5657  0.377976       0.00  0.538058   0.5          0         0             0   \n",
       "5768  0.110521       0.00  0.854646   1.0          0         0             0   \n",
       "6280  0.200830       0.00  0.538058   1.0          0         0             0   \n",
       "6591  0.608220       0.00  0.448622   0.2          0         0             0   \n",
       "6602  0.449051       0.00  0.373640   0.0          0         0             0   \n",
       "6637  0.332922       0.00  0.398820   0.2          0         0             0   \n",
       "7748  0.442519       0.00  0.361263   0.3          0         0             0   \n",
       "7976  0.445133       0.00  0.520298   0.0          0         1             0   \n",
       "8357  0.244699       0.00  0.886967   0.7          0         0             0   \n",
       "8424  0.374173       0.00  0.766887   0.5          1         0             0   \n",
       "8737  0.483186       0.00  0.327765   0.1          0         0             0   \n",
       "8842  0.075173       0.00  0.305522   0.8          0         0             0   \n",
       "\n",
       "      make_Corvette  make_DS  make_Fiat  ...  model_S7  model_SLC 250  \\\n",
       "77                0        0          0  ...         0              0   \n",
       "101               0        0          0  ...         0              0   \n",
       "824               0        1          0  ...         0              0   \n",
       "1032              0        0          0  ...         0              0   \n",
       "2314              0        0          0  ...         0              0   \n",
       "2468              0        0          0  ...         0              0   \n",
       "2550              0        0          0  ...         0              0   \n",
       "3623              0        0          0  ...         1              0   \n",
       "3684              0        0          0  ...         0              0   \n",
       "4405              0        0          1  ...         0              0   \n",
       "5657              0        0          0  ...         0              1   \n",
       "5768              0        0          0  ...         0              0   \n",
       "6280              0        0          0  ...         0              0   \n",
       "6591              0        0          0  ...         0              0   \n",
       "6602              0        0          0  ...         0              0   \n",
       "6637              0        0          0  ...         0              0   \n",
       "7748              0        1          0  ...         0              0   \n",
       "7976              0        0          0  ...         0              0   \n",
       "8357              1        0          0  ...         0              0   \n",
       "8424              0        0          0  ...         1              0   \n",
       "8737              0        0          1  ...         0              0   \n",
       "8842              0        0          0  ...         0              0   \n",
       "\n",
       "      model_T5 Shuttle  fuel_Diesel  fuel_Electric  fuel_Gasoline  \\\n",
       "77                   0            0              1              0   \n",
       "101                  0            0              0              1   \n",
       "824                  0            0              0              1   \n",
       "1032                 0            0              0              1   \n",
       "2314                 0            0              0              1   \n",
       "2468                 0            0              0              1   \n",
       "2550                 0            1              0              0   \n",
       "3623                 0            0              0              1   \n",
       "3684                 0            0              1              0   \n",
       "4405                 0            0              1              0   \n",
       "5657                 0            1              0              0   \n",
       "5768                 0            0              0              1   \n",
       "6280                 0            0              1              0   \n",
       "6591                 1            1              0              0   \n",
       "6602                 0            0              0              1   \n",
       "6637                 0            1              0              0   \n",
       "7748                 0            1              0              0   \n",
       "7976                 0            0              0              1   \n",
       "8357                 0            0              0              1   \n",
       "8424                 0            0              0              1   \n",
       "8737                 0            0              0              1   \n",
       "8842                 0            0              0              1   \n",
       "\n",
       "      gear_Automatic  gear_Manual   price  pre_backtrans_pred  \n",
       "77                 1            0   83870        3.996071e+09  \n",
       "101                1            0   34950        5.998644e+09  \n",
       "824                0            1    8500        7.560187e+09  \n",
       "1032               1            0   35000        3.379601e+08  \n",
       "2314               1            0   99800        3.948626e+10  \n",
       "2468               1            0   86885        3.379601e+08  \n",
       "2550               1            0    9985        5.998644e+09  \n",
       "3623               1            0   39925        7.201592e+09  \n",
       "3684               1            0   45555        6.188076e+09  \n",
       "4405               1            0   33994        7.184330e+09  \n",
       "5657               1            0   29950        3.379601e+08  \n",
       "5768               1            0  175470        3.131556e+09  \n",
       "6280               1            0   52490        6.188076e+09  \n",
       "6591               0            1   17300        6.188076e+09  \n",
       "6602               0            1    1190        1.721461e+09  \n",
       "6637               1            0    9900        1.609189e+09  \n",
       "7748               0            1    7480        7.560187e+09  \n",
       "7976               1            0   10900        6.466283e+06  \n",
       "8357               0            1   94900        1.463901e+10  \n",
       "8424               1            0   44930        7.201592e+09  \n",
       "8737               0            1    3400        6.316963e+09  \n",
       "8842               0            1   55900        3.722491e+09  \n",
       "\n",
       "[22 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_before = lr_pred_df.index\n",
    "rows_before = lr_pred_df.shape[0]\n",
    "\n",
    "lr_pred_df = lr_pred_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "index_after = lr_pred_df.index\n",
    "rows_after = lr_pred_df.shape[0]\n",
    "\n",
    "removed_indices = index_before.difference(index_after)\n",
    "removed_rows = rows_before - rows_after\n",
    "percent_removed = (removed_rows / rows_before) * 100\n",
    "\n",
    "removed_rows_X_test = X_test.iloc[removed_indices]\n",
    "removed_rows_y_test = y_test.iloc[removed_indices]\n",
    "removed_rows_df = pd.concat([removed_rows_X_test, removed_rows_y_test], axis=1)\n",
    "removed_rows_df['pre_backtrans_pred'] = lr_pred.flatten()[removed_indices]\n",
    "filtered_removed_rows_df = removed_rows_df.loc[:, (removed_rows_df != 0).any()]\n",
    "\n",
    "print('Rows before removing NaNs and Infs:', rows_before)\n",
    "print('Rows after removing NaNs and Infs:', rows_after)\n",
    "print('Number of rows removed:', removed_rows)\n",
    "print('Percentage of rows removed:', percent_removed, '%')\n",
    "\n",
    "print(\"Problematic rows in X_test and y_test:\")\n",
    "filtered_removed_rows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the linear regression model leads to extremely high predicted values for the problematic rows. Therefore, the back transformation fails, leading to infinite values. The full linear regression model therefore appears to be unsuitable. After removing the problematic rows, the evaluation metrics are calculated.  However, it should be noted that these can only be interpreted to a limited extent, as not all predictions are taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.928132</td>\n",
       "      <td>0.920122</td>\n",
       "      <td>4906.257588</td>\n",
       "      <td>8.711491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model        r2    r2_adj         rmse   seconds\n",
       "0    lr  0.928132  0.920122  4906.257588  8.711491"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r2 = r2_score(lr_pred_df['y_test'], lr_pred_df['pred'])\n",
    "lr_r2_adj = 1 - (1 - lr_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "lr_rmse = np.sqrt(mean_squared_error(lr_pred_df['y_test'], lr_pred_df['pred']))\n",
    "lr_seconds = lr_delta.seconds + lr_delta.microseconds/1E6\n",
    "\n",
    "lr_evaluation = pd.DataFrame({\n",
    "    'model': ['lr'],\n",
    "    'r2': [lr_r2],\n",
    "    'r2_adj': [lr_r2_adj],\n",
    "    'rmse': [lr_rmse],\n",
    "    'seconds': [lr_seconds]\n",
    "})\n",
    "\n",
    "lr_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model, model predictions and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_model, '../models/models/lr_model.pkl')\n",
    "lr_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"lr_evaluation.csv\"), index=False)\n",
    "lr_res = pd.DataFrame(lr_pred)\n",
    "lr_res.index = X_test.index\n",
    "lr_res.columns = [\"prediction\"]\n",
    "lr_res.to_csv(\"../models/predictions/lr_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"alpha\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 19:04:18,003] A new study created in memory with name: no-name-3a79e641-7114-40c5-878d-6b257df9fb34\n",
      "[I 2024-02-09 19:04:28,295] Trial 0 finished with value: 0.7013207160161288 and parameters: {'alpha': 10243321.458660385}. Best is trial 0 with value: 0.7013207160161288.\n",
      "[I 2024-02-09 19:08:33,305] Trial 1 finished with value: 0.16394805195471082 and parameters: {'alpha': 5.96865180528638e-07}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:38,564] Trial 2 finished with value: 0.7013207160161288 and parameters: {'alpha': 401158.3420221274}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:43,155] Trial 3 finished with value: 0.7013207160161288 and parameters: {'alpha': 836.8044150727266}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:47,370] Trial 4 finished with value: 0.7013207160161288 and parameters: {'alpha': 9.170761659151827}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:51,996] Trial 5 finished with value: 0.7013207160161288 and parameters: {'alpha': 19802190.19690238}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:57,308] Trial 6 finished with value: 0.7013207160161288 and parameters: {'alpha': 0.7737208697265361}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:09:02,472] Trial 7 finished with value: 0.7013207160161288 and parameters: {'alpha': 583869975.9426675}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:09:07,763] Trial 8 finished with value: 0.7013207160161288 and parameters: {'alpha': 16.59259553215712}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:13:27,760] Trial 9 finished with value: 0.16389049879721082 and parameters: {'alpha': 4.189615204360501e-06}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:18:02,866] Trial 10 finished with value: 0.1642869282150733 and parameters: {'alpha': 1.5559380994842274e-09}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:04,134] Trial 11 finished with value: 0.16392637328019716 and parameters: {'alpha': 8.293296603310652e-07}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:33,279] Trial 12 finished with value: 0.18119144097822065 and parameters: {'alpha': 0.0001176924519363625}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:41,408] Trial 13 finished with value: 0.19476144323139022 and parameters: {'alpha': 0.00040154110507913105}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:27:03,745] Trial 14 finished with value: 0.16428741892204218 and parameters: {'alpha': 1.3738759021723526e-09}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:27:25,977] Trial 15 finished with value: 0.18270563257386369 and parameters: {'alpha': 0.00013193783928244787}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:31:27,367] Trial 16 finished with value: 0.16388752627560566 and parameters: {'alpha': 1.9516900194665794e-06}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:31:33,200] Trial 17 finished with value: 0.36277456810536285 and parameters: {'alpha': 0.023835213172484666}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:35:34,949] Trial 18 finished with value: 0.16396417131572627 and parameters: {'alpha': 4.4734639418797396e-07}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:35:41,088] Trial 19 finished with value: 0.2325967385786135 and parameters: {'alpha': 0.0049580607036358495}. Best is trial 16 with value: 0.16388752627560566.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.9516900194665794e-06}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coarse_study = optuna.create_study(direction='minimize')\n",
    "lasso_coarse_study.optimize(lasso_coarse_objective, n_trials=20)\n",
    "lasso_coarse_best_params = lasso_coarse_study.best_params\n",
    "lasso_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 22:05:22,906] A new study created in memory with name: no-name-63e3e229-f876-40ed-8234-230ff6f3fbd4\n",
      "[I 2024-02-09 22:09:08,328] Trial 0 finished with value: 0.16387247936991217 and parameters: {'alpha': 3.3649281346240794e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:12:05,381] Trial 1 finished with value: 0.1639890023075982 and parameters: {'alpha': 3.50098099799282e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:15:26,831] Trial 2 finished with value: 0.163960839806155 and parameters: {'alpha': 5.928976887895147e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:18:52,154] Trial 3 finished with value: 0.16397385111604876 and parameters: {'alpha': 6.14406310830036e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:22:16,639] Trial 4 finished with value: 0.1639914131708431 and parameters: {'alpha': 3.420306904942853e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:25:35,740] Trial 5 finished with value: 0.16389030004894473 and parameters: {'alpha': 1.7282593114263626e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:28:27,564] Trial 6 finished with value: 0.16410428364448676 and parameters: {'alpha': 1.218444651509368e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:32:26,535] Trial 7 finished with value: 0.16391171948516461 and parameters: {'alpha': 1.1433959832426737e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:36:52,828] Trial 8 finished with value: 0.1640306902358677 and parameters: {'alpha': 2.4066228261469425e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:41:08,549] Trial 9 finished with value: 0.1639714224820903 and parameters: {'alpha': 4.184258984029763e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:44:42,454] Trial 10 finished with value: 0.1638721501595497 and parameters: {'alpha': 2.6013635911554013e-06}. Best is trial 10 with value: 0.1638721501595497.\n",
      "[I 2024-02-09 22:47:52,229] Trial 11 finished with value: 0.1638733838028849 and parameters: {'alpha': 2.5045966591931192e-06}. Best is trial 10 with value: 0.1638721501595497.\n",
      "[I 2024-02-09 22:51:08,058] Trial 12 finished with value: 0.1638704204936376 and parameters: {'alpha': 3.1599970196135527e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 22:54:12,961] Trial 13 finished with value: 0.1642964438463651 and parameters: {'alpha': 9.432099132371166e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 22:57:04,913] Trial 14 finished with value: 0.1639171660351192 and parameters: {'alpha': 1.000406276073766e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:00:16,670] Trial 15 finished with value: 0.1638716458846639 and parameters: {'alpha': 3.3134566972147136e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:03:31,246] Trial 16 finished with value: 0.16391227454344606 and parameters: {'alpha': 4.890587954669088e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:06:42,724] Trial 17 finished with value: 0.16388997548880066 and parameters: {'alpha': 1.660075376658924e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:09:58,191] Trial 18 finished with value: 0.16393612069400657 and parameters: {'alpha': 7.020916880724997e-07}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:13:05,571] Trial 19 finished with value: 0.1638863020391366 and parameters: {'alpha': 4.007489351379599e-06}. Best is trial 12 with value: 0.1638704204936376.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 3.1599970196135527e-06}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_fine_study = optuna.create_study(direction='minimize')\n",
    "lasso_fine_study.optimize(lasso_fine_objective, n_trials=20)\n",
    "lasso_fine_best_params = lasso_fine_study.best_params\n",
    "lasso_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 3.1599970196135527e-06."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+01, tolerance: 1.813e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=lasso_fine_best_params['alpha'])\n",
    "lasso_start = datetime.now()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_stop = datetime.now()\n",
    "lasso_delta = lasso_stop - lasso_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lasso</td>\n",
       "      <td>0.949303</td>\n",
       "      <td>0.943652</td>\n",
       "      <td>4152.140941</td>\n",
       "      <td>53.182399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse    seconds\n",
       "0  lasso  0.949303  0.943652  4152.140941  53.182399"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pred_inverse = np.expm1(lasso_pred)\n",
    "\n",
    "lasso_r2 = r2_score(y_test, lasso_pred_inverse)\n",
    "lasso_r2_adj = 1 - (1 - lasso_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso_pred_inverse))\n",
    "lasso_seconds = lasso_delta.seconds + lasso_delta.microseconds/1E6\n",
    "\n",
    "lasso_evaluation = pd.DataFrame({\n",
    "    'model': ['lasso'],\n",
    "    'r2': [lasso_r2],\n",
    "    'r2_adj': [lasso_r2_adj],\n",
    "    'rmse': [lasso_rmse],\n",
    "    'seconds': [lasso_seconds]\n",
    "})\n",
    "\n",
    "lasso_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lasso_model, '../models/models/lasso_model.pkl')\n",
    "lasso_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"lasso_evaluation.csv\"), index=False)\n",
    "lasso_res = pd.DataFrame(lasso_pred)\n",
    "lasso_res.index = X_test.index\n",
    "lasso_res.columns = [\"prediction\"]\n",
    "lasso_res.to_csv(\"../models/predictions/lasso_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the ridge hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"alpha\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:36:40,634] A new study created in memory with name: no-name-980e92ef-e28b-4d0c-9bce-ce0fa5a6cbc8\n",
      "[I 2024-02-09 23:36:50,021] Trial 0 finished with value: 0.16424857262649997 and parameters: {'alpha': 1.1743120410150176}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:36:55,919] Trial 1 finished with value: 0.17098125868126882 and parameters: {'alpha': 10.535200575024227}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:01,370] Trial 2 finished with value: 0.18931491451252808 and parameters: {'alpha': 49.63657417215814}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:07,791] Trial 3 finished with value: 0.6998189954419571 and parameters: {'alpha': 3193783.064577547}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:15,744] Trial 4 finished with value: 0.418584998793132 and parameters: {'alpha': 3237.982475531299}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:21,331] Trial 5 finished with value: 0.16423515997889412 and parameters: {'alpha': 0.0011326405463555165}. Best is trial 5 with value: 0.16423515997889412.\n",
      "[I 2024-02-09 23:37:27,549] Trial 6 finished with value: 0.1642526386536567 and parameters: {'alpha': 7.429034513348599e-08}. Best is trial 5 with value: 0.16423515997889412.\n",
      "[I 2024-02-09 23:37:34,372] Trial 7 finished with value: 0.16392721865235738 and parameters: {'alpha': 0.19240665124910455}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:40,883] Trial 8 finished with value: 0.1642524203400879 and parameters: {'alpha': 1.3382682436137682e-05}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:48,372] Trial 9 finished with value: 0.3310280296650617 and parameters: {'alpha': 950.7938589978701}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:54,213] Trial 10 finished with value: 0.7012831868065359 and parameters: {'alpha': 128446984.1820619}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:02,379] Trial 11 finished with value: 0.16424410662714894 and parameters: {'alpha': 0.0005335539293584385}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:09,669] Trial 12 finished with value: 0.1642179117599708 and parameters: {'alpha': 0.002420256368322732}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:17,090] Trial 13 finished with value: 0.1642236633579564 and parameters: {'alpha': 0.0019697676693886247}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:23,797] Trial 14 finished with value: 0.16425256409070527 and parameters: {'alpha': 1.7487675638354417e-09}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:30,444] Trial 15 finished with value: 0.16408842621761263 and parameters: {'alpha': 0.025092035966330875}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:36,664] Trial 16 finished with value: 0.16393077952482277 and parameters: {'alpha': 0.18400424820661812}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:42,263] Trial 17 finished with value: 0.6516804304298842 and parameters: {'alpha': 80685.02833280104}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:48,678] Trial 18 finished with value: 0.16425257782827488 and parameters: {'alpha': 3.84440080229112e-06}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:54,365] Trial 19 finished with value: 0.16389690495513123 and parameters: {'alpha': 0.350978657363417}. Best is trial 19 with value: 0.16389690495513123.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.350978657363417}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coarse_study = optuna.create_study(direction='minimize')\n",
    "ridge_coarse_study.optimize(ridge_coarse_objective, n_trials=20)\n",
    "ridge_coarse_best_params = ridge_coarse_study.best_params\n",
    "ridge_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-1 to 10^0, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-1, 1e0, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:45:01,863] A new study created in memory with name: no-name-91b9b771-80b7-49b9-80a7-d1fbd13061b2\n",
      "[I 2024-02-09 23:45:14,934] Trial 0 finished with value: 0.16400502975907394 and parameters: {'alpha': 0.7560482810597207}. Best is trial 0 with value: 0.16400502975907394.\n",
      "[I 2024-02-09 23:45:22,776] Trial 1 finished with value: 0.16391336117257108 and parameters: {'alpha': 0.4982289691237173}. Best is trial 1 with value: 0.16391336117257108.\n",
      "[I 2024-02-09 23:45:30,822] Trial 2 finished with value: 0.16389780865442807 and parameters: {'alpha': 0.38887340984488644}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:36,991] Trial 3 finished with value: 0.16395869677401717 and parameters: {'alpha': 0.13233143481954387}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:44,444] Trial 4 finished with value: 0.16405648400067147 and parameters: {'alpha': 0.8585941195554095}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:52,589] Trial 5 finished with value: 0.16391635792561252 and parameters: {'alpha': 0.51139079319983}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:59,183] Trial 6 finished with value: 0.16396780912400896 and parameters: {'alpha': 0.11911485905324662}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:05,564] Trial 7 finished with value: 0.16390734804538704 and parameters: {'alpha': 0.4680901106966353}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:11,013] Trial 8 finished with value: 0.16400470884976642 and parameters: {'alpha': 0.7553616900580229}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:17,070] Trial 9 finished with value: 0.16405325075217167 and parameters: {'alpha': 0.8525143787247235}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:22,905] Trial 10 finished with value: 0.16391928040257817 and parameters: {'alpha': 0.21359960912263237}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:28,892] Trial 11 finished with value: 0.16389820786328974 and parameters: {'alpha': 0.31969121104570075}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:35,402] Trial 12 finished with value: 0.1639023192823017 and parameters: {'alpha': 0.2832853467432849}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:41,044] Trial 13 finished with value: 0.16390086966129563 and parameters: {'alpha': 0.2934759493059888}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:47,281] Trial 14 finished with value: 0.16393161201813272 and parameters: {'alpha': 0.1821199978310215}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:53,117] Trial 15 finished with value: 0.16389749915406876 and parameters: {'alpha': 0.38295643925989914}. Best is trial 15 with value: 0.16389749915406876.\n",
      "[I 2024-02-09 23:46:58,844] Trial 16 finished with value: 0.16390755296290732 and parameters: {'alpha': 0.46922871536559546}. Best is trial 15 with value: 0.16389749915406876.\n",
      "[I 2024-02-09 23:47:04,814] Trial 17 finished with value: 0.16389692410089277 and parameters: {'alpha': 0.36415511361529757}. Best is trial 17 with value: 0.16389692410089277.\n",
      "[I 2024-02-09 23:47:10,641] Trial 18 finished with value: 0.16392000223252576 and parameters: {'alpha': 0.21150234764808162}. Best is trial 17 with value: 0.16389692410089277.\n",
      "[I 2024-02-09 23:47:16,674] Trial 19 finished with value: 0.16395667946604914 and parameters: {'alpha': 0.6418344458281925}. Best is trial 17 with value: 0.16389692410089277.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.36415511361529757}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_fine_study = optuna.create_study(direction='minimize')\n",
    "ridge_fine_study.optimize(ridge_fine_objective, n_trials=20)\n",
    "ridge_fine_best_params = ridge_fine_study.best_params\n",
    "ridge_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 0.36415511361529757."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ridge model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=ridge_fine_best_params['alpha'])\n",
    "ridge_start = datetime.now()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_stop = datetime.now()\n",
    "ridge_delta = ridge_stop - ridge_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.933437</td>\n",
       "      <td>4512.857727</td>\n",
       "      <td>1.733712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse   seconds\n",
       "0  ridge  0.940112  0.933437  4512.857727  1.733712"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred_inverse = np.expm1(ridge_pred)\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_pred_inverse)\n",
    "ridge_r2_adj = 1 - (1 - ridge_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred_inverse))\n",
    "ridge_seconds = ridge_delta.seconds + ridge_delta.microseconds/1E6\n",
    "\n",
    "ridge_evaluation = pd.DataFrame({\n",
    "    'model': ['ridge'],\n",
    "    'r2': [ridge_r2],\n",
    "    'r2_adj': [ridge_r2_adj],\n",
    "    'rmse': [ridge_rmse],\n",
    "    'seconds': [ridge_seconds]\n",
    "})\n",
    "\n",
    "ridge_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ridge_model, '../models/models/ridge_model.pkl')\n",
    "ridge_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"ridge_evaluation.csv\"), index=False)\n",
    "ridge_res = pd.DataFrame(ridge_pred)\n",
    "ridge_res.index = X_test.index\n",
    "ridge_res.columns = [\"prediction\"]\n",
    "ridge_res.to_csv(\"../models/predictions/ridge_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the elastic net hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameters \"alpha\" and the \"l1 ratio\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "    elasticnet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(elasticnet, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:56:44,342] A new study created in memory with name: no-name-6bcc7919-3a04-4ee0-9f52-ca1229989486\n",
      "[I 2024-02-09 23:56:51,473] Trial 0 finished with value: 0.7013207160161288 and parameters: {'alpha': 73.05249792172569, 'l1_ratio': 0.48929492242600703}. Best is trial 0 with value: 0.7013207160161288.\n",
      "[I 2024-02-10 00:00:09,481] Trial 1 finished with value: 0.16428393249434645 and parameters: {'alpha': 3.698522250451831e-09, 'l1_ratio': 0.8038315597375395}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:00:13,032] Trial 2 finished with value: 0.7013207160161288 and parameters: {'alpha': 1.5506251802243947, 'l1_ratio': 0.7408186330293501}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:00:20,307] Trial 3 finished with value: 0.19518038543879007 and parameters: {'alpha': 0.0009063432259673031, 'l1_ratio': 0.3853263311447038}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:03:35,356] Trial 4 finished with value: 0.1641418528787575 and parameters: {'alpha': 1.953388364083622e-05, 'l1_ratio': 0.24998298340864977}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:03:39,818] Trial 5 finished with value: 0.6762410378123718 and parameters: {'alpha': 0.2588615293534744, 'l1_ratio': 0.6401614670553343}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:03:43,337] Trial 6 finished with value: 0.7013207160161288 and parameters: {'alpha': 461506459.78979677, 'l1_ratio': 0.2917224538861707}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:04:05,417] Trial 7 finished with value: 0.17457499374843988 and parameters: {'alpha': 0.00011669544236095001, 'l1_ratio': 0.5469958637591138}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:04:09,454] Trial 8 finished with value: 0.7013207160161288 and parameters: {'alpha': 46.88583042289867, 'l1_ratio': 0.9387840720063189}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:07:08,238] Trial 9 finished with value: 0.16428284349749916 and parameters: {'alpha': 4.436459353150842e-09, 'l1_ratio': 0.829349968956481}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:07:11,831] Trial 10 finished with value: 0.7013207160161288 and parameters: {'alpha': 419374.1610050739, 'l1_ratio': 0.0591208092504627}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:10:26,406] Trial 11 finished with value: 0.16429010552054119 and parameters: {'alpha': 1.2851391740585937e-09, 'l1_ratio': 0.16591110027542266}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:13:32,373] Trial 12 finished with value: 0.163898912310572 and parameters: {'alpha': 2.430224145742283e-06, 'l1_ratio': 0.26693419316393463}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:16:26,724] Trial 13 finished with value: 0.16482331734295858 and parameters: {'alpha': 3.3972548471724546e-05, 'l1_ratio': 0.24422576212520347}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:19:44,589] Trial 14 finished with value: 0.16401969010551784 and parameters: {'alpha': 1.9202343558372625e-06, 'l1_ratio': 0.016463116107983122}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:22:38,035] Trial 15 finished with value: 0.16398825103045694 and parameters: {'alpha': 2.940995746691278e-06, 'l1_ratio': 0.0003477535378410765}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:25:47,918] Trial 16 finished with value: 0.16414102352827914 and parameters: {'alpha': 3.924890203763333e-07, 'l1_ratio': 0.13365013465467537}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:25:57,167] Trial 17 finished with value: 0.24972103952583052 and parameters: {'alpha': 0.005815297145431985, 'l1_ratio': 0.4316055634986944}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:28:59,431] Trial 18 finished with value: 0.1642940794652116 and parameters: {'alpha': 2.149269812074249e-07, 'l1_ratio': 0.005606785602731035}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:29:04,861] Trial 19 finished with value: 0.4055965574201214 and parameters: {'alpha': 0.041656007753575044, 'l1_ratio': 0.3636937379329225}. Best is trial 12 with value: 0.163898912310572.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.430224145742283e-06, 'l1_ratio': 0.26693419316393463}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_coarse_study = optuna.create_study(direction='minimize')\n",
    "elasticnet_coarse_study.optimize(elasticnet_coarse_objective, n_trials=20)\n",
    "elasticnet_coarse_best_params = elasticnet_coarse_study.best_params\n",
    "elasticnet_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6 and l1 ratio 10^-1 to 10^0, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.1, 1)\n",
    "    elasticnet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(elasticnet, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 09:23:34,290] A new study created in memory with name: no-name-4cba7b1c-2cca-4da3-af2e-fa5f5c067ab6\n",
      "[I 2024-02-10 09:26:20,845] Trial 0 finished with value: 0.16418770947259687 and parameters: {'alpha': 1.0611453153664617e-07, 'l1_ratio': 0.45916353635923446}. Best is trial 0 with value: 0.16418770947259687.\n",
      "[I 2024-02-10 09:28:53,523] Trial 1 finished with value: 0.16424038449077666 and parameters: {'alpha': 1.1420750225616437e-07, 'l1_ratio': 0.20522381933850875}. Best is trial 0 with value: 0.16418770947259687.\n",
      "[I 2024-02-10 09:31:25,821] Trial 2 finished with value: 0.164071997567935 and parameters: {'alpha': 2.2423122236687345e-07, 'l1_ratio': 0.7992642642371942}. Best is trial 2 with value: 0.164071997567935.\n",
      "[I 2024-02-10 09:34:30,205] Trial 3 finished with value: 0.163878654344104 and parameters: {'alpha': 2.7176833107958028e-06, 'l1_ratio': 0.8533991235497324}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:37:28,901] Trial 4 finished with value: 0.16403566654567386 and parameters: {'alpha': 3.8672324580177e-07, 'l1_ratio': 0.4779933638437509}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:40:14,404] Trial 5 finished with value: 0.16426449705444274 and parameters: {'alpha': 1.2352729671948035e-07, 'l1_ratio': 0.11864678826135235}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:43:20,331] Trial 6 finished with value: 0.16399453027677183 and parameters: {'alpha': 8.882144294199369e-07, 'l1_ratio': 0.26812969118131524}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:46:18,464] Trial 7 finished with value: 0.1639218301965095 and parameters: {'alpha': 1.3016987416790963e-06, 'l1_ratio': 0.8879587462092405}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:49:20,839] Trial 8 finished with value: 0.16414538449437077 and parameters: {'alpha': 1.3227615989421992e-07, 'l1_ratio': 0.6735551811223504}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:53:25,940] Trial 9 finished with value: 0.1639805050956207 and parameters: {'alpha': 6.212372021216146e-07, 'l1_ratio': 0.48379704172784355}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:56:51,463] Trial 10 finished with value: 0.16409438544538807 and parameters: {'alpha': 7.4853764761918e-06, 'l1_ratio': 0.980642817284316}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 10:00:03,432] Trial 11 finished with value: 0.163892051764027 and parameters: {'alpha': 2.6974131168859096e-06, 'l1_ratio': 0.9834199581022974}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 10:03:38,787] Trial 12 finished with value: 0.16386670705706036 and parameters: {'alpha': 3.158809602865725e-06, 'l1_ratio': 0.7514172088257848}. Best is trial 12 with value: 0.16386670705706036.\n",
      "[I 2024-02-10 10:07:23,140] Trial 13 finished with value: 0.16385814266479345 and parameters: {'alpha': 3.857663967160253e-06, 'l1_ratio': 0.7066615186842985}. Best is trial 13 with value: 0.16385814266479345.\n",
      "[I 2024-02-10 10:10:46,173] Trial 14 finished with value: 0.1640450607697227 and parameters: {'alpha': 9.768596323596865e-06, 'l1_ratio': 0.6498272480615328}. Best is trial 13 with value: 0.16385814266479345.\n",
      "[I 2024-02-10 10:14:17,357] Trial 15 finished with value: 0.16385630151770753 and parameters: {'alpha': 3.943231695230683e-06, 'l1_ratio': 0.6838802956392738}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:18:30,114] Trial 16 finished with value: 0.16387238768157503 and parameters: {'alpha': 5.678956147492921e-06, 'l1_ratio': 0.6208721457218576}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:22:34,463] Trial 17 finished with value: 0.16391712987021884 and parameters: {'alpha': 1.5976337135550126e-06, 'l1_ratio': 0.38409142706861504}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:25:38,933] Trial 18 finished with value: 0.1638632877846918 and parameters: {'alpha': 4.121466072459011e-06, 'l1_ratio': 0.7361049942557509}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:28:20,014] Trial 19 finished with value: 0.16390116999106363 and parameters: {'alpha': 1.7092668821787898e-06, 'l1_ratio': 0.5798680598412542}. Best is trial 15 with value: 0.16385630151770753.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 3.943231695230683e-06, 'l1_ratio': 0.6838802956392738}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_fine_study = optuna.create_study(direction='minimize')\n",
    "elasticnet_fine_study.optimize(elasticnet_fine_objective, n_trials=20)\n",
    "elasticnet_fine_best_params = elasticnet_fine_study.best_params\n",
    "elasticnet_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 3.943231695230683e-06 and l1 ratio = 0.6838802956392738."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the elastic net model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.988e+01, tolerance: 1.813e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elasticnet_model = ElasticNet(alpha=elasticnet_fine_best_params['alpha'], l1_ratio=elasticnet_fine_best_params['l1_ratio'])\n",
    "elasticnet_start = datetime.now()\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "elasticnet_pred = elasticnet_model.predict(X_test)\n",
    "elasticnet_stop = datetime.now()\n",
    "elasticnet_delta = elasticnet_stop - elasticnet_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.948092</td>\n",
       "      <td>0.942306</td>\n",
       "      <td>4201.461942</td>\n",
       "      <td>77.137834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model        r2    r2_adj         rmse    seconds\n",
       "0  elasticnet  0.948092  0.942306  4201.461942  77.137834"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_pred_inverse = np.expm1(elasticnet_pred)\n",
    "\n",
    "elasticnet_r2 = r2_score(y_test, elasticnet_pred_inverse)\n",
    "elasticnet_r2_adj = 1 - (1 - elasticnet_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "elasticnet_rmse = np.sqrt(mean_squared_error(y_test, elasticnet_pred_inverse))\n",
    "elasticnet_seconds = elasticnet_delta.seconds + elasticnet_delta.microseconds/1E6\n",
    "\n",
    "elasticnet_evaluation = pd.DataFrame({\n",
    "    'model': ['elasticnet'],\n",
    "    'r2': [elasticnet_r2],\n",
    "    'r2_adj': [elasticnet_r2_adj],\n",
    "    'rmse': [elasticnet_rmse],\n",
    "    'seconds': [elasticnet_seconds]\n",
    "})\n",
    "\n",
    "elasticnet_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(elasticnet_model, '../models/models/elasticnet_model.pkl')\n",
    "elasticnet_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"elasticnet_evaluation.csv\"), index=False)\n",
    "elasticnet_res = pd.DataFrame(elasticnet_pred)\n",
    "elasticnet_res.index = X_test.index\n",
    "elasticnet_res.columns = [\"prediction\"]\n",
    "elasticnet_res.to_csv(\"../models/predictions/elasticnet_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Robust Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. Huber Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the huber regression hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameters \"alpha\" and \"epsilon\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 1.0, 2.0)\n",
    "    huber = HuberRegressor(alpha=alpha, epsilon=epsilon)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(huber, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 15:47:23,505] A new study created in memory with name: no-name-47385cf4-8fe6-4b75-81f1-82d2eb27299f\n",
      "[I 2024-02-10 15:49:30,618] Trial 0 finished with value: 0.17015942234510364 and parameters: {'alpha': 0.2774699984085081, 'epsilon': 1.519249436181226}. Best is trial 0 with value: 0.17015942234510364.\n",
      "[I 2024-02-10 15:51:30,413] Trial 1 finished with value: 0.1714768544964337 and parameters: {'alpha': 9.775799499879854e-08, 'epsilon': 1.2290931912935026}. Best is trial 0 with value: 0.17015942234510364.\n",
      "[I 2024-02-10 15:53:41,531] Trial 2 finished with value: 0.16982439214150563 and parameters: {'alpha': 0.22676287042545554, 'epsilon': 1.8267688394701462}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 15:55:54,629] Trial 3 finished with value: 0.17027320860399597 and parameters: {'alpha': 3.1321014496836833e-07, 'epsilon': 1.7555549734712543}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 15:58:04,948] Trial 4 finished with value: 0.17030356318401868 and parameters: {'alpha': 0.0704131919475868, 'epsilon': 1.7391566886000884}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:00:12,451] Trial 5 finished with value: 0.170072255007298 and parameters: {'alpha': 0.0005541709414891476, 'epsilon': 1.7715477680346516}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:00:37,308] Trial 6 finished with value: 0.41733578260187204 and parameters: {'alpha': 7302.00797716347, 'epsilon': 1.2189539253408153}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:01:11,908] Trial 7 finished with value: 0.6816947301191714 and parameters: {'alpha': 337506.45712914603, 'epsilon': 1.9691412216114723}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:03:19,233] Trial 8 finished with value: 0.17039827167799793 and parameters: {'alpha': 0.010558255774634224, 'epsilon': 1.690776817406741}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:05:41,304] Trial 9 finished with value: 0.17157736313297617 and parameters: {'alpha': 20.979477252849264, 'epsilon': 1.5151379559337288}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:06:14,408] Trial 10 finished with value: 0.7108211117995801 and parameters: {'alpha': 683395070.673746, 'epsilon': 1.0061645545302738}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:08:25,569] Trial 11 finished with value: 0.16923431638158884 and parameters: {'alpha': 7.37950301489792e-05, 'epsilon': 1.9886807708950724}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:10:39,016] Trial 12 finished with value: 0.1694651918829237 and parameters: {'alpha': 2.9211412984681153e-05, 'epsilon': 1.9943181087027557}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:12:47,224] Trial 13 finished with value: 0.16943434411739558 and parameters: {'alpha': 1.0530757080550188e-09, 'epsilon': 1.9885557423760372}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:14:57,079] Trial 14 finished with value: 0.16971687087997073 and parameters: {'alpha': 1.7222302802036026e-09, 'epsilon': 1.9105705777410327}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:17:04,741] Trial 15 finished with value: 0.17000930310591286 and parameters: {'alpha': 1.1074523598280377e-09, 'epsilon': 1.6308953092133633}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:19:12,257] Trial 16 finished with value: 0.1695399944885847 and parameters: {'alpha': 1.3024131082866523e-05, 'epsilon': 1.88608724758239}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:21:12,544] Trial 17 finished with value: 0.17160200795982386 and parameters: {'alpha': 3.691044973705169e-07, 'epsilon': 1.3081358195483577}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:23:16,865] Trial 18 finished with value: 0.17012204089796898 and parameters: {'alpha': 2.8063941907652296e-05, 'epsilon': 1.609421672092024}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:25:22,321] Trial 19 finished with value: 0.17018304909094353 and parameters: {'alpha': 2.8198455011986057e-08, 'epsilon': 1.8606944339747558}. Best is trial 11 with value: 0.16923431638158884.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 7.37950301489792e-05, 'epsilon': 1.9886807708950724}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_coarse_study = optuna.create_study(direction='minimize')\n",
    "huber_coarse_study.optimize(huber_coarse_objective, n_trials=20)\n",
    "huber_coarse_best_params = huber_coarse_study.best_params\n",
    "huber_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6 and epsilon near 2, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 1.9, 2.0)\n",
    "    huber = HuberRegressor(alpha=alpha, epsilon=epsilon)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(huber, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 14:25:45,437] A new study created in memory with name: no-name-277db13d-15d2-452b-91f4-05b591138b2a\n",
      "[I 2024-02-10 14:28:23,261] Trial 0 finished with value: 0.16946093642638044 and parameters: {'alpha': 2.102586098773178e-07, 'epsilon': 1.9317520120367464}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:30:28,051] Trial 1 finished with value: 0.16974317582031384 and parameters: {'alpha': 1.9436391916273176e-07, 'epsilon': 1.9107556093185707}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:32:34,315] Trial 2 finished with value: 0.16953010917304015 and parameters: {'alpha': 2.301815405272179e-06, 'epsilon': 1.905033163742058}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:34:33,496] Trial 3 finished with value: 0.16966976655452734 and parameters: {'alpha': 3.356769436674778e-06, 'epsilon': 1.9473879754958292}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:36:35,010] Trial 4 finished with value: 0.16922765585564442 and parameters: {'alpha': 3.7073096832852122e-06, 'epsilon': 1.9540079080431}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:38:35,826] Trial 5 finished with value: 0.16942797901372325 and parameters: {'alpha': 9.330137945313375e-07, 'epsilon': 1.955646440724383}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:40:36,199] Trial 6 finished with value: 0.16939158131355123 and parameters: {'alpha': 6.865079761948513e-07, 'epsilon': 1.9773210184585013}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:42:37,046] Trial 7 finished with value: 0.16941457665618806 and parameters: {'alpha': 4.574028083149486e-06, 'epsilon': 1.940037621821646}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:44:38,882] Trial 8 finished with value: 0.16933531921949987 and parameters: {'alpha': 1.2720554262357714e-06, 'epsilon': 1.9487695954769726}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:46:38,966] Trial 9 finished with value: 0.16957630074956415 and parameters: {'alpha': 3.7236099422569674e-06, 'epsilon': 1.980517614085017}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:48:40,870] Trial 10 finished with value: 0.16921927225422212 and parameters: {'alpha': 8.627070834562276e-06, 'epsilon': 1.995917458517765}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:50:38,808] Trial 11 finished with value: 0.16938796828763142 and parameters: {'alpha': 9.136854435750553e-06, 'epsilon': 1.9963534795415259}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:52:38,858] Trial 12 finished with value: 0.16967737518259907 and parameters: {'alpha': 7.886152988440147e-06, 'epsilon': 1.9995070689878087}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:54:54,958] Trial 13 finished with value: 0.16949166396223964 and parameters: {'alpha': 1.6925231173086753e-06, 'epsilon': 1.9664403768546874}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:57:06,718] Trial 14 finished with value: 0.1695112070302357 and parameters: {'alpha': 4.4691130309461986e-07, 'epsilon': 1.9201119001686593}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:59:12,961] Trial 15 finished with value: 0.16979681353803583 and parameters: {'alpha': 6.844892803877861e-06, 'epsilon': 1.9808512282372495}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:01:21,913] Trial 16 finished with value: 0.16969843302940663 and parameters: {'alpha': 5.019823754025895e-06, 'epsilon': 1.964156609143939}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:03:42,789] Trial 17 finished with value: 0.16963643421171734 and parameters: {'alpha': 2.520001250750877e-06, 'epsilon': 1.9266957765677928}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:05:52,335] Trial 18 finished with value: 0.1692286120387035 and parameters: {'alpha': 9.104614933675814e-06, 'epsilon': 1.986616205097269}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:07:57,811] Trial 19 finished with value: 0.16962897613266864 and parameters: {'alpha': 5.509361416140461e-06, 'epsilon': 1.9659346578804895}. Best is trial 10 with value: 0.16921927225422212.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 8.627070834562276e-06, 'epsilon': 1.995917458517765}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_fine_study = optuna.create_study(direction='minimize')\n",
    "huber_fine_study.optimize(huber_fine_objective, n_trials=20)\n",
    "huber_fine_best_params = huber_fine_study.best_params\n",
    "huber_fine_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 8.627070834562276e-06, 'epsilon': 1.995917458517765}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 8.627070834562276e-06 and epsilon = 1.995917458517765."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Huber regression model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fit-ted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_model = HuberRegressor(alpha=huber_fine_best_params['alpha'], epsilon=huber_fine_best_params['epsilon'], max_iter=10000)\n",
    "huber_start = datetime.now()\n",
    "huber_model.fit(X_train, y_train.values.ravel())\n",
    "huber_pred = huber_model.predict(X_test)\n",
    "huber_stop = datetime.now()\n",
    "huber_delta = huber_stop - huber_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huber</td>\n",
       "      <td>0.950388</td>\n",
       "      <td>0.944858</td>\n",
       "      <td>4107.468443</td>\n",
       "      <td>1056.937912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse      seconds\n",
       "0  huber  0.950388  0.944858  4107.468443  1056.937912"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_pred_inverse = np.expm1(huber_pred)\n",
    "\n",
    "huber_r2 = r2_score(y_test, huber_pred_inverse)\n",
    "huber_r2_adj = 1 - (1 - huber_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "huber_rmse = np.sqrt(mean_squared_error(y_test, huber_pred_inverse))\n",
    "huber_seconds = huber_delta.seconds + huber_delta.microseconds/1E6\n",
    "\n",
    "huber_evaluation = pd.DataFrame({\n",
    "    'model': ['huber'],\n",
    "    'r2': [huber_r2],\n",
    "    'r2_adj': [huber_r2_adj],\n",
    "    'rmse': [huber_rmse],\n",
    "    'seconds': [huber_seconds]\n",
    "})\n",
    "\n",
    "huber_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(huber_model, '../models/models/huber_model.pkl')\n",
    "huber_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"huber_evaluation.csv\"), index=False)\n",
    "huber_res = pd.DataFrame(huber_pred)\n",
    "huber_res.index = X_test.index\n",
    "huber_res.columns = [\"prediction\"]\n",
    "huber_res.to_csv(\"../models/predictions/huber_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the Quantile regression hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameters \"alpha\" and \"epsilon\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    quantile = trial.suggest_float('quantile', 0, 1.0)\n",
    "    quantile_regressor = QuantileRegressor(alpha=alpha, quantile=quantile)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(quantile_regressor, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 19:48:21,322] A new study created in memory with name: no-name-44941ee8-d115-4e8a-a87a-071283512174\n",
      "[I 2024-02-10 19:52:14,654] Trial 0 finished with value: 0.1972568877155163 and parameters: {'alpha': 1.484268718308485e-05, 'quantile': 0.22936699901226265}. Best is trial 0 with value: 0.1972568877155163.\n",
      "[I 2024-02-10 19:53:41,543] Trial 1 finished with value: 0.8930991022683878 and parameters: {'alpha': 13497871.075306997, 'quantile': 0.7816180825835011}. Best is trial 0 with value: 0.1972568877155163.\n",
      "[I 2024-02-10 19:57:09,497] Trial 2 finished with value: 0.16749112269001215 and parameters: {'alpha': 4.302528127718235e-06, 'quantile': 0.5536598113738292}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 19:58:14,089] Trial 3 finished with value: 1.1664174837436694 and parameters: {'alpha': 0.17266249627736224, 'quantile': 0.058166990855073486}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 19:59:15,775] Trial 4 finished with value: 1.438284981149006 and parameters: {'alpha': 9.856518698465962, 'quantile': 0.9525814490208674}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:01:16,902] Trial 5 finished with value: 0.7113954835483058 and parameters: {'alpha': 261916.06571360774, 'quantile': 0.4933847219967691}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:03:44,457] Trial 6 finished with value: 0.27997990186929356 and parameters: {'alpha': 0.012243037997549486, 'quantile': 0.3502994590282257}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:05:05,149] Trial 7 finished with value: 1.0149237708846415 and parameters: {'alpha': 3.288516650114552, 'quantile': 0.8364697406279757}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:06:20,395] Trial 8 finished with value: 1.0134349543568402 and parameters: {'alpha': 82.05546412834175, 'quantile': 0.12278919028853508}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:08:11,230] Trial 9 finished with value: 0.7013366926656063 and parameters: {'alpha': 171.2270625063646, 'quantile': 0.5591551655347065}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:11:43,696] Trial 10 finished with value: 0.17365450227816331 and parameters: {'alpha': 2.601388009488819e-09, 'quantile': 0.6247534455001972}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:15:01,976] Trial 11 finished with value: 0.17352485991327526 and parameters: {'alpha': 4.2292440174547056e-09, 'quantile': 0.6231847834886124}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:18:32,876] Trial 12 finished with value: 0.182991354154344 and parameters: {'alpha': 4.148653189823318e-08, 'quantile': 0.6883927376330687}. Best is trial 2 with value: 0.16749112269001215.\n",
      "[I 2024-02-10 20:21:58,533] Trial 13 finished with value: 0.1668546170405898 and parameters: {'alpha': 1.110326963289598e-05, 'quantile': 0.42712470981811507}. Best is trial 13 with value: 0.1668546170405898.\n",
      "[I 2024-02-10 20:25:20,651] Trial 14 finished with value: 0.1787144254114227 and parameters: {'alpha': 5.7571024893683396e-05, 'quantile': 0.3633013301183305}. Best is trial 13 with value: 0.1668546170405898.\n",
      "[I 2024-02-10 20:28:47,108] Trial 15 finished with value: 0.1715989094492601 and parameters: {'alpha': 4.771156575419688e-05, 'quantile': 0.41226927014435566}. Best is trial 13 with value: 0.1668546170405898.\n",
      "[I 2024-02-10 20:32:13,782] Trial 16 finished with value: 0.16554867016925426 and parameters: {'alpha': 2.5148222550759484e-06, 'quantile': 0.472165721106035}. Best is trial 16 with value: 0.16554867016925426.\n",
      "[I 2024-02-10 20:35:07,111] Trial 17 finished with value: 0.2644832264884549 and parameters: {'alpha': 0.004495982668125725, 'quantile': 0.24789432868106448}. Best is trial 16 with value: 0.16554867016925426.\n",
      "[I 2024-02-10 20:38:32,305] Trial 18 finished with value: 0.19472997935906194 and parameters: {'alpha': 4.2283930807883195e-07, 'quantile': 0.23715425997807787}. Best is trial 16 with value: 0.16554867016925426.\n",
      "[I 2024-02-10 20:41:41,675] Trial 19 finished with value: 0.19716926773204163 and parameters: {'alpha': 0.0007118844674340887, 'quantile': 0.4247555375884514}. Best is trial 16 with value: 0.16554867016925426.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.5148222550759484e-06, 'quantile': 0.472165721106035}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_coarse_study = optuna.create_study(direction='minimize')\n",
    "quantile_coarse_study.optimize(quantile_coarse_objective, n_trials=20)\n",
    "quantile_coarse_best_params = quantile_coarse_study.best_params\n",
    "quantile_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6 and quantile near 50%, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    quantile = trial.suggest_float('quantile', 0.4, 0.6)\n",
    "    quantile_regressor = QuantileRegressor(alpha=alpha, quantile=quantile)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(quantile_regressor, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 21:18:57,987] A new study created in memory with name: no-name-44f01fe2-420c-4b75-acc5-7a64e4feb4ef\n",
      "[I 2024-02-10 21:22:39,238] Trial 0 finished with value: 0.1689371778717976 and parameters: {'alpha': 7.113259094226004e-06, 'quantile': 0.5773948560320911}. Best is trial 0 with value: 0.1689371778717976.\n",
      "[I 2024-02-10 21:26:09,335] Trial 1 finished with value: 0.16542629369480316 and parameters: {'alpha': 1.1264750222011006e-06, 'quantile': 0.5030638204633192}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:29:45,033] Trial 2 finished with value: 0.16593816380258478 and parameters: {'alpha': 8.917089108907226e-07, 'quantile': 0.4563644388645848}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:33:18,550] Trial 3 finished with value: 0.16567255173782647 and parameters: {'alpha': 3.5417794742522604e-06, 'quantile': 0.46351084921808444}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:36:48,664] Trial 4 finished with value: 0.1660983313395736 and parameters: {'alpha': 4.948669532017241e-07, 'quantile': 0.4515978513039252}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:40:21,596] Trial 5 finished with value: 0.16681610022891863 and parameters: {'alpha': 1.3936569324013159e-06, 'quantile': 0.5384490552708573}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:43:48,277] Trial 6 finished with value: 0.16562121416063266 and parameters: {'alpha': 4.611733799739779e-07, 'quantile': 0.48374703027324134}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:47:17,744] Trial 7 finished with value: 0.16543843511452233 and parameters: {'alpha': 9.571888230215298e-07, 'quantile': 0.4965692758651388}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:50:54,842] Trial 8 finished with value: 0.16744952257608142 and parameters: {'alpha': 5.907301028802897e-06, 'quantile': 0.5521081426420137}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:54:26,967] Trial 9 finished with value: 0.1679294083029349 and parameters: {'alpha': 4.280319412415087e-06, 'quantile': 0.4073225086926277}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 21:57:56,069] Trial 10 finished with value: 0.1666298377514308 and parameters: {'alpha': 1.1197776417210676e-07, 'quantile': 0.5282865128023262}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:01:29,257] Trial 11 finished with value: 0.165611566316522 and parameters: {'alpha': 1.9209245337351823e-06, 'quantile': 0.5079970190918746}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:04:55,492] Trial 12 finished with value: 0.16555700001315635 and parameters: {'alpha': 5.550722038947613e-07, 'quantile': 0.49621966420922403}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:08:24,794] Trial 13 finished with value: 0.16733538760265115 and parameters: {'alpha': 2.1220814224371208e-07, 'quantile': 0.4223749825973173}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:11:53,333] Trial 14 finished with value: 0.17011809776813194 and parameters: {'alpha': 2.2521675250812716e-06, 'quantile': 0.5907516530855162}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:15:45,505] Trial 15 finished with value: 0.16608279478611213 and parameters: {'alpha': 9.048081353345289e-07, 'quantile': 0.515885740661704}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:19:16,098] Trial 16 finished with value: 0.1657168007530514 and parameters: {'alpha': 2.494891040168942e-07, 'quantile': 0.4814209366674397}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:22:45,983] Trial 17 finished with value: 0.16759196903381143 and parameters: {'alpha': 1.3551971908380145e-06, 'quantile': 0.5553309014571175}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:26:12,755] Trial 18 finished with value: 0.16656221628213658 and parameters: {'alpha': 2.4126775141128605e-06, 'quantile': 0.4336855858774744}. Best is trial 1 with value: 0.16542629369480316.\n",
      "[I 2024-02-10 22:29:49,610] Trial 19 finished with value: 0.16565209172046175 and parameters: {'alpha': 3.0880596889690213e-07, 'quantile': 0.4790372060498792}. Best is trial 1 with value: 0.16542629369480316.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.1264750222011006e-06, 'quantile': 0.5030638204633192}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_fine_study = optuna.create_study(direction='minimize')\n",
    "quantile_fine_study.optimize(quantile_fine_objective, n_trials=20)\n",
    "quantile_fine_best_params = quantile_fine_study.best_params\n",
    "quantile_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 1.1264750222011006e-06 and quantile = 0.5030638204633192."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the quantile regression model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fit-ted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\sklearn\\utils\\validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "quantile_model = QuantileRegressor(alpha=quantile_fine_best_params['alpha'], quantile=quantile_fine_best_params['quantile'])\n",
    "quantile_start = datetime.now()\n",
    "quantile_model.fit(X_train, y_train)\n",
    "quantile_pred = quantile_model.predict(X_test)\n",
    "quantile_stop = datetime.now()\n",
    "quantile_delta = quantile_stop - quantile_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quantile</td>\n",
       "      <td>0.952018</td>\n",
       "      <td>0.94667</td>\n",
       "      <td>4039.448262</td>\n",
       "      <td>110.754906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model        r2   r2_adj         rmse     seconds\n",
       "0  quantile  0.952018  0.94667  4039.448262  110.754906"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_pred_inverse = np.expm1(quantile_pred)\n",
    "\n",
    "quantile_r2 = r2_score(y_test, quantile_pred_inverse)\n",
    "quantile_r2_adj = 1 - (1 - quantile_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "quantile_rmse = np.sqrt(mean_squared_error(y_test, quantile_pred_inverse))\n",
    "quantile_seconds = quantile_delta.seconds + quantile_delta.microseconds/1E6\n",
    "\n",
    "quantile_evaluation = pd.DataFrame({\n",
    "    'model': ['quantile'],\n",
    "    'r2': [quantile_r2],\n",
    "    'r2_adj': [quantile_r2_adj],\n",
    "    'rmse': [quantile_rmse],\n",
    "    'seconds': [quantile_seconds]\n",
    "})\n",
    "\n",
    "quantile_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(quantile_model, '../models/models/quantile_model.pkl')\n",
    "quantile_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"quantile_evaluation.csv\"), index=False)\n",
    "quantile_res = pd.DataFrame(quantile_pred)\n",
    "quantile_res.index = X_test.index\n",
    "quantile_res.columns = [\"prediction\"]\n",
    "quantile_res.to_csv(\"../models/predictions/quantile_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3. RANSAC Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4. Theil Sen Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the k-Nearest Neighbors Regression (KNN) (hyper)parameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"n_neighbors\", \"metric\", \"weights\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_coarse_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 100)\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'cosine'])\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, metric=metric, weights=weights)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(knn, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 12:51:40,678] A new study created in memory with name: no-name-c44fdcdb-d356-4703-96a7-bfb74ed1bfc2\n",
      "[I 2024-02-12 12:53:49,544] Trial 0 finished with value: 0.2261274055871673 and parameters: {'n_neighbors': 95, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 0 with value: 0.2261274055871673.\n",
      "[I 2024-02-12 12:55:04,637] Trial 1 finished with value: 0.2091143201231799 and parameters: {'n_neighbors': 51, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 1 with value: 0.2091143201231799.\n",
      "[I 2024-02-12 12:55:53,572] Trial 2 finished with value: 0.19542551131956953 and parameters: {'n_neighbors': 6, 'metric': 'euclidean', 'weights': 'uniform'}. Best is trial 2 with value: 0.19542551131956953.\n",
      "[I 2024-02-12 12:56:57,028] Trial 3 finished with value: 0.18298070254262128 and parameters: {'n_neighbors': 8, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:11:25,748] Trial 4 finished with value: 0.21850975797905042 and parameters: {'n_neighbors': 94, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:27:33,554] Trial 5 finished with value: 0.18919294070762005 and parameters: {'n_neighbors': 22, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:41:58,402] Trial 6 finished with value: 0.21990035683452872 and parameters: {'n_neighbors': 100, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:42:47,915] Trial 7 finished with value: 0.1995847852379531 and parameters: {'n_neighbors': 34, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:43:36,574] Trial 8 finished with value: 0.2091143201231799 and parameters: {'n_neighbors': 51, 'metric': 'euclidean', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:58:04,566] Trial 9 finished with value: 0.28260587184332203 and parameters: {'n_neighbors': 72, 'metric': 'manhattan', 'weights': 'uniform'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 13:58:58,598] Trial 10 finished with value: 0.20624434726797744 and parameters: {'n_neighbors': 1, 'metric': 'cosine', 'weights': 'uniform'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:00:03,387] Trial 11 finished with value: 0.18515582839132794 and parameters: {'n_neighbors': 22, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:01:08,253] Trial 12 finished with value: 0.18515582839132794 and parameters: {'n_neighbors': 22, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:02:12,693] Trial 13 finished with value: 0.18437156079287673 and parameters: {'n_neighbors': 17, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:03:15,834] Trial 14 finished with value: 0.26145136059935126 and parameters: {'n_neighbors': 40, 'metric': 'cosine', 'weights': 'uniform'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:04:18,244] Trial 15 finished with value: 0.18335958188419776 and parameters: {'n_neighbors': 12, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:05:21,632] Trial 16 finished with value: 0.19088584433774752 and parameters: {'n_neighbors': 64, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:06:25,207] Trial 17 finished with value: 0.1830570101188909 and parameters: {'n_neighbors': 10, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:07:27,898] Trial 18 finished with value: 0.2560657574748075 and parameters: {'n_neighbors': 35, 'metric': 'cosine', 'weights': 'uniform'}. Best is trial 3 with value: 0.18298070254262128.\n",
      "[I 2024-02-12 14:08:21,679] Trial 19 finished with value: 0.20624434726797744 and parameters: {'n_neighbors': 1, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 3 with value: 0.18298070254262128.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 8, 'metric': 'cosine', 'weights': 'distance'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_coarse_study = optuna.create_study(direction='minimize')\n",
    "knn_coarse_study.optimize(knn_coarse_objective, n_trials=20)\n",
    "knn_coarse_best_params = knn_coarse_study.best_params\n",
    "knn_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved at  n_neighbors < 25, a metric of either cosine or manhattan, and weights based on distance. Therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fine_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 25)\n",
    "    metric = trial.suggest_categorical('metric', ['manhattan', 'cosine'])\n",
    "    weights = trial.suggest_categorical('weights', ['distance'])\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, metric=metric, weights=weights)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(knn, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 14:20:42,627] A new study created in memory with name: no-name-690b2630-1c27-44bb-b8e4-7aec5666ce27\n",
      "[I 2024-02-12 14:21:50,264] Trial 0 finished with value: 0.18301881387123556 and parameters: {'n_neighbors': 9, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 0 with value: 0.18301881387123556.\n",
      "[I 2024-02-12 14:38:46,774] Trial 1 finished with value: 0.18976022309971669 and parameters: {'n_neighbors': 23, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 0 with value: 0.18301881387123556.\n",
      "[I 2024-02-12 14:39:42,554] Trial 2 finished with value: 0.19082744487686298 and parameters: {'n_neighbors': 2, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 0 with value: 0.18301881387123556.\n",
      "[I 2024-02-12 14:54:17,713] Trial 3 finished with value: 0.190884885222314 and parameters: {'n_neighbors': 25, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 0 with value: 0.18301881387123556.\n",
      "[I 2024-02-12 15:08:49,199] Trial 4 finished with value: 0.1809072269208439 and parameters: {'n_neighbors': 10, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 15:23:15,610] Trial 5 finished with value: 0.18361057605921688 and parameters: {'n_neighbors': 14, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 15:38:45,683] Trial 6 finished with value: 0.190884885222314 and parameters: {'n_neighbors': 25, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 15:39:48,244] Trial 7 finished with value: 0.18363886131428966 and parameters: {'n_neighbors': 14, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 15:40:51,186] Trial 8 finished with value: 0.18290139417633652 and parameters: {'n_neighbors': 7, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 15:55:14,523] Trial 9 finished with value: 0.18361057605921688 and parameters: {'n_neighbors': 14, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:09:38,209] Trial 10 finished with value: 0.18734724138624453 and parameters: {'n_neighbors': 19, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:10:41,381] Trial 11 finished with value: 0.1833748900398749 and parameters: {'n_neighbors': 6, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:11:44,054] Trial 12 finished with value: 0.18298070254262128 and parameters: {'n_neighbors': 8, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:12:38,703] Trial 13 finished with value: 0.20624434726797744 and parameters: {'n_neighbors': 1, 'metric': 'cosine', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:26:53,635] Trial 14 finished with value: 0.1809072269208439 and parameters: {'n_neighbors': 10, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:41:42,081] Trial 15 finished with value: 0.18155507832121426 and parameters: {'n_neighbors': 11, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 4 with value: 0.1809072269208439.\n",
      "[I 2024-02-12 16:55:59,142] Trial 16 finished with value: 0.1803959457672639 and parameters: {'n_neighbors': 4, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 16 with value: 0.1803959457672639.\n",
      "[I 2024-02-12 17:10:20,014] Trial 17 finished with value: 0.17952051013851675 and parameters: {'n_neighbors': 5, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 17 with value: 0.17952051013851675.\n",
      "[I 2024-02-12 17:24:41,421] Trial 18 finished with value: 0.1803959457672639 and parameters: {'n_neighbors': 4, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 17 with value: 0.17952051013851675.\n",
      "[I 2024-02-12 17:39:19,245] Trial 19 finished with value: 0.1803959457672639 and parameters: {'n_neighbors': 4, 'metric': 'manhattan', 'weights': 'distance'}. Best is trial 17 with value: 0.17952051013851675.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5, 'metric': 'manhattan', 'weights': 'distance'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_fine_study = optuna.create_study(direction='minimize')\n",
    "knn_fine_study.optimize(knn_fine_objective, n_trials=20)\n",
    "knn_fine_best_params = knn_fine_study.best_params\n",
    "knn_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at 'n_neighbors' = 5, 'metric' = 'manhattan' and 'weights' = 'distance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the knn regression model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=knn_fine_best_params['n_neighbors'], \n",
    "                                metric=knn_fine_best_params['metric'],\n",
    "                                weights=knn_fine_best_params['weights'])\n",
    "knn_start = datetime.now()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "knn_stop = datetime.now()\n",
    "knn_delta = knn_stop - knn_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.904055</td>\n",
       "      <td>0.893361</td>\n",
       "      <td>5712.046169</td>\n",
       "      <td>257.094118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model        r2    r2_adj         rmse     seconds\n",
       "0   knn  0.904055  0.893361  5712.046169  257.094118"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred_inverse = np.expm1(knn_pred)\n",
    "\n",
    "knn_r2 = r2_score(y_test, knn_pred_inverse)\n",
    "knn_r2_adj = 1 - (1 - knn_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "knn_rmse = np.sqrt(mean_squared_error(y_test, knn_pred_inverse))\n",
    "knn_seconds = knn_delta.seconds + knn_delta.microseconds/1E6\n",
    "\n",
    "knn_evaluation = pd.DataFrame({\n",
    "    'model': ['knn'],\n",
    "    'r2': [knn_r2],\n",
    "    'r2_adj': [knn_r2_adj],\n",
    "    'rmse': [knn_rmse],\n",
    "    'seconds': [knn_seconds]\n",
    "})\n",
    "knn_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn_model, '../models/models/knn_model.pkl')\n",
    "knn_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"knn_evaluation.csv\"), index=False)\n",
    "knn_res = pd.DataFrame(knn_pred)\n",
    "knn_res.index = X_test.index\n",
    "knn_res.columns = [\"prediction\"]\n",
    "knn_res.to_csv(\"../models/predictions/knn_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1. Multi-Layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the Support Vector Regression (SVR) hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"C\", \"gamma\", \"epsilon\" and \"kernel\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_coarse_objective(trial):\n",
    "    C = trial.suggest_float('C', 1e-6, 1e3, log=True)\n",
    "    tol = trial.suggest_float(\"tol\", 1e-9, 1e-1, log=True)\n",
    "    epsilon = trial.suggest_float(\"epsilon\", 1e-3, 1e1, log=True)\n",
    "    loss = trial.suggest_categorical(\"loss\", ['epsilon_insensitive', 'squared_epsilon_insensitive'])\n",
    "    svr = LinearSVR(C=C, loss=loss, tol=tol, epsilon=epsilon)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(svr, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 20:53:12,579] A new study created in memory with name: no-name-68a1573b-1c66-4b67-9685-c7c6b8b3491e\n",
      "[I 2024-02-14 20:53:35,772] Trial 0 finished with value: 3.1052196142578756 and parameters: {'C': 1.3683239321714658e-05, 'tol': 2.0625339754568704e-09, 'epsilon': 0.010674442309464882, 'loss': 'squared_epsilon_insensitive'}. Best is trial 0 with value: 3.1052196142578756.\n",
      "[I 2024-02-14 20:53:44,409] Trial 1 finished with value: 0.16474006267580193 and parameters: {'C': 6.291914240097194, 'tol': 0.064427774518623, 'epsilon': 0.05692119564645714, 'loss': 'squared_epsilon_insensitive'}. Best is trial 1 with value: 0.16474006267580193.\n",
      "[I 2024-02-14 20:53:48,779] Trial 2 finished with value: 0.19697368771351925 and parameters: {'C': 0.016482491312162464, 'tol': 5.687953353024018e-05, 'epsilon': 0.07245354574398293, 'loss': 'squared_epsilon_insensitive'}. Best is trial 1 with value: 0.16474006267580193.\n",
      "[I 2024-02-14 20:53:53,594] Trial 3 finished with value: 0.17002828612852489 and parameters: {'C': 0.06758343741450935, 'tol': 3.924158580165189e-06, 'epsilon': 0.052371830782583326, 'loss': 'epsilon_insensitive'}. Best is trial 1 with value: 0.16474006267580193.\n",
      "[I 2024-02-14 20:54:18,941] Trial 4 finished with value: 0.24041967550249144 and parameters: {'C': 215.40332918182048, 'tol': 0.0025102317103541825, 'epsilon': 0.00537595505433082, 'loss': 'epsilon_insensitive'}. Best is trial 1 with value: 0.16474006267580193.\n",
      "[I 2024-02-14 20:54:25,485] Trial 5 finished with value: 0.16577499678586688 and parameters: {'C': 0.24414757129098236, 'tol': 4.943647927871231e-08, 'epsilon': 0.004157327391972819, 'loss': 'epsilon_insensitive'}. Best is trial 1 with value: 0.16474006267580193.\n",
      "[I 2024-02-14 20:54:50,873] Trial 6 finished with value: 0.16411103409109246 and parameters: {'C': 10.468915496110482, 'tol': 3.7470987375764065e-07, 'epsilon': 0.005576181714130822, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:54:54,585] Trial 7 finished with value: 0.3601146635719112 and parameters: {'C': 0.09876699936083601, 'tol': 3.0674661716345626e-08, 'epsilon': 1.1456529471750414, 'loss': 'epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:54:58,817] Trial 8 finished with value: 9.346164448319971 and parameters: {'C': 1.3169211551676704e-06, 'tol': 0.0018164413210325484, 'epsilon': 1.4621852710589147, 'loss': 'epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:55:02,694] Trial 9 finished with value: 0.22375566426564114 and parameters: {'C': 0.005979274033081356, 'tol': 0.01083546308055608, 'epsilon': 0.005111324523638557, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:55:26,619] Trial 10 finished with value: 0.22927545541599184 and parameters: {'C': 923.2120720109428, 'tol': 4.887324784572825e-06, 'epsilon': 0.0011047986720599352, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:55:34,136] Trial 11 finished with value: 0.18359181603545655 and parameters: {'C': 10.479218680016668, 'tol': 0.09793769945097634, 'epsilon': 0.3298512953249356, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:55:54,271] Trial 12 finished with value: 0.1641628818753658 and parameters: {'C': 9.283676634639303, 'tol': 6.0199485981349676e-05, 'epsilon': 0.026374653710393756, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:55:57,806] Trial 13 finished with value: 4.652837240565892 and parameters: {'C': 5.92622545917705, 'tol': 8.893239872758268e-05, 'epsilon': 6.6421399983311336, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:56:02,408] Trial 14 finished with value: 0.3950447167341093 and parameters: {'C': 0.0005180209646772663, 'tol': 3.3211960297391237e-07, 'epsilon': 0.014653097960365489, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:56:26,338] Trial 15 finished with value: 0.16482267693541003 and parameters: {'C': 36.722206194391774, 'tol': 9.12225439006218e-05, 'epsilon': 0.0010000730658069634, 'loss': 'squared_epsilon_insensitive'}. Best is trial 6 with value: 0.16411103409109246.\n",
      "[I 2024-02-14 20:56:33,530] Trial 16 finished with value: 0.16405898936826452 and parameters: {'C': 1.2972909167443012, 'tol': 7.231119513167499e-07, 'epsilon': 0.021282355887059613, 'loss': 'squared_epsilon_insensitive'}. Best is trial 16 with value: 0.16405898936826452.\n",
      "[I 2024-02-14 20:56:37,603] Trial 17 finished with value: 0.17288860524590843 and parameters: {'C': 0.763004146491291, 'tol': 3.4616032412163317e-07, 'epsilon': 0.2316231001123361, 'loss': 'squared_epsilon_insensitive'}. Best is trial 16 with value: 0.16405898936826452.\n",
      "[I 2024-02-14 20:56:41,783] Trial 18 finished with value: 0.30351851600367585 and parameters: {'C': 0.001562722359737681, 'tol': 4.143344995977423e-09, 'epsilon': 0.02494563100003949, 'loss': 'squared_epsilon_insensitive'}. Best is trial 16 with value: 0.16405898936826452.\n",
      "[I 2024-02-14 20:56:49,292] Trial 19 finished with value: 0.1640760008433574 and parameters: {'C': 0.7901196117634538, 'tol': 1.375257942312532e-06, 'epsilon': 0.0024267582989657326, 'loss': 'squared_epsilon_insensitive'}. Best is trial 16 with value: 0.16405898936826452.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.2972909167443012,\n",
       " 'tol': 7.231119513167499e-07,\n",
       " 'epsilon': 0.021282355887059613,\n",
       " 'loss': 'squared_epsilon_insensitive'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_coarse_study = optuna.create_study(direction='minimize')\n",
    "svr_coarse_study.optimize(svr_coarse_objective, n_trials=20)\n",
    "svr_coarse_best_params = svr_coarse_study.best_params\n",
    "svr_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within range of \n",
    "10^-1 and 10^2 for \"C\", \n",
    "10^-7 and 10^-2 for \"tol\", \n",
    "10^-3 and 10^-1 for \"epsilon\" and\n",
    "a \"squared_epsilon_insensitive\" type \"loss, \n",
    "therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Decision Trees Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.1. Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.2. Bagging Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.3. Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.4. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.6. LightGBM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.7. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.8. Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.9. Stacking Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.10. Voting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.11. Histogram-based Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Dimensionality-Reduced Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
