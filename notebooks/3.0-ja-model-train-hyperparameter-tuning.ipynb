{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\")\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train linear regression model and measure computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression() \n",
    "lr_start = datetime.now()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_stop = datetime.now()\n",
    "lr_delta = lr_stop - lr_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the log-transformation applied to the target variable y_train during data preprocessing to ensure normality and linearity, it is necessary to reverse this transformation on the predictions before assessing the model using metrics such as RMSE and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in expm1\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_test_log = np.log1p(y_test.to_numpy())\n",
    "\n",
    "lr_pred_df = pd.DataFrame({'pred': lr_pred.flatten(), 'y_test': y_test_log.flatten()})\n",
    "\n",
    "lr_pred_df['pred'] = np.expm1(lr_pred_df['pred'])\n",
    "lr_pred_df['y_test'] = np.expm1(lr_pred_df['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the back-transformation, NaNs and Infs occurred for some rows. These entries are eliminated, and the indices of the removed rows are stored to identify the observations that led to these issues. Additionally, the total count and the relative proportion of dropped rows are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before removing NaNs and Infs: 9215\n",
      "Rows after removing NaNs and Infs: 9193\n",
      "Number of rows removed: 22\n",
      "Percentage of rows removed: 0.23874118285404233 %\n",
      "Problematic rows in X_test and y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mileage</th>\n",
       "      <th>offerType</th>\n",
       "      <th>hp</th>\n",
       "      <th>year</th>\n",
       "      <th>make_Audi</th>\n",
       "      <th>make_BMW</th>\n",
       "      <th>make_Bentley</th>\n",
       "      <th>make_Corvette</th>\n",
       "      <th>make_DS</th>\n",
       "      <th>make_Fiat</th>\n",
       "      <th>...</th>\n",
       "      <th>model_S7</th>\n",
       "      <th>model_SLC 250</th>\n",
       "      <th>model_T5 Shuttle</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_Electric</th>\n",
       "      <th>fuel_Gasoline</th>\n",
       "      <th>gear_Automatic</th>\n",
       "      <th>gear_Manual</th>\n",
       "      <th>price</th>\n",
       "      <th>pre_backtrans_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.139248</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83870</td>\n",
       "      <td>3.996071e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34950</td>\n",
       "      <td>5.998644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.339380</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8500</td>\n",
       "      <td>7.560187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.283372</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.678830</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>0.403326</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.810958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99800</td>\n",
       "      <td>3.948626e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>0.126833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.770530</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86885</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0.554074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.493344</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9985</td>\n",
       "      <td>5.998644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>0.398366</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39925</td>\n",
       "      <td>7.201592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>0.208001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45555</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.409779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33994</td>\n",
       "      <td>7.184330e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>0.377976</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29950</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.854646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175470</td>\n",
       "      <td>3.131556e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>0.200830</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52490</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>0.608220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.448622</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17300</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>0.449051</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.373640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1190</td>\n",
       "      <td>1.721461e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>0.332922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.398820</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9900</td>\n",
       "      <td>1.609189e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748</th>\n",
       "      <td>0.442519</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.361263</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7480</td>\n",
       "      <td>7.560187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>0.445133</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.520298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10900</td>\n",
       "      <td>6.466283e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8357</th>\n",
       "      <td>0.244699</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.886967</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94900</td>\n",
       "      <td>1.463901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8424</th>\n",
       "      <td>0.374173</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.766887</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44930</td>\n",
       "      <td>7.201592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>0.483186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.327765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3400</td>\n",
       "      <td>6.316963e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>0.075173</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.305522</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55900</td>\n",
       "      <td>3.722491e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mileage  offerType        hp  year  make_Audi  make_BMW  make_Bentley  \\\n",
       "77    0.139248       0.50  0.538058   1.0          0         0             0   \n",
       "101   0.300000       0.00  0.732819   0.6          0         0             0   \n",
       "824   0.406800       0.00  0.339380   0.5          0         0             0   \n",
       "1032  0.283372       0.00  0.678830   0.7          0         1             0   \n",
       "2314  0.403326       0.00  0.810958   0.0          0         0             1   \n",
       "2468  0.126833       0.00  0.770530   0.8          0         0             0   \n",
       "2550  0.554074       0.00  0.493344   0.4          0         0             0   \n",
       "3623  0.398366       0.00  0.744444   0.3          1         0             0   \n",
       "3684  0.208001       0.50  0.538058   1.0          0         0             0   \n",
       "4405  0.020801       0.75  0.409779   1.0          0         0             0   \n",
       "5657  0.377976       0.00  0.538058   0.5          0         0             0   \n",
       "5768  0.110521       0.00  0.854646   1.0          0         0             0   \n",
       "6280  0.200830       0.00  0.538058   1.0          0         0             0   \n",
       "6591  0.608220       0.00  0.448622   0.2          0         0             0   \n",
       "6602  0.449051       0.00  0.373640   0.0          0         0             0   \n",
       "6637  0.332922       0.00  0.398820   0.2          0         0             0   \n",
       "7748  0.442519       0.00  0.361263   0.3          0         0             0   \n",
       "7976  0.445133       0.00  0.520298   0.0          0         1             0   \n",
       "8357  0.244699       0.00  0.886967   0.7          0         0             0   \n",
       "8424  0.374173       0.00  0.766887   0.5          1         0             0   \n",
       "8737  0.483186       0.00  0.327765   0.1          0         0             0   \n",
       "8842  0.075173       0.00  0.305522   0.8          0         0             0   \n",
       "\n",
       "      make_Corvette  make_DS  make_Fiat  ...  model_S7  model_SLC 250  \\\n",
       "77                0        0          0  ...         0              0   \n",
       "101               0        0          0  ...         0              0   \n",
       "824               0        1          0  ...         0              0   \n",
       "1032              0        0          0  ...         0              0   \n",
       "2314              0        0          0  ...         0              0   \n",
       "2468              0        0          0  ...         0              0   \n",
       "2550              0        0          0  ...         0              0   \n",
       "3623              0        0          0  ...         1              0   \n",
       "3684              0        0          0  ...         0              0   \n",
       "4405              0        0          1  ...         0              0   \n",
       "5657              0        0          0  ...         0              1   \n",
       "5768              0        0          0  ...         0              0   \n",
       "6280              0        0          0  ...         0              0   \n",
       "6591              0        0          0  ...         0              0   \n",
       "6602              0        0          0  ...         0              0   \n",
       "6637              0        0          0  ...         0              0   \n",
       "7748              0        1          0  ...         0              0   \n",
       "7976              0        0          0  ...         0              0   \n",
       "8357              1        0          0  ...         0              0   \n",
       "8424              0        0          0  ...         1              0   \n",
       "8737              0        0          1  ...         0              0   \n",
       "8842              0        0          0  ...         0              0   \n",
       "\n",
       "      model_T5 Shuttle  fuel_Diesel  fuel_Electric  fuel_Gasoline  \\\n",
       "77                   0            0              1              0   \n",
       "101                  0            0              0              1   \n",
       "824                  0            0              0              1   \n",
       "1032                 0            0              0              1   \n",
       "2314                 0            0              0              1   \n",
       "2468                 0            0              0              1   \n",
       "2550                 0            1              0              0   \n",
       "3623                 0            0              0              1   \n",
       "3684                 0            0              1              0   \n",
       "4405                 0            0              1              0   \n",
       "5657                 0            1              0              0   \n",
       "5768                 0            0              0              1   \n",
       "6280                 0            0              1              0   \n",
       "6591                 1            1              0              0   \n",
       "6602                 0            0              0              1   \n",
       "6637                 0            1              0              0   \n",
       "7748                 0            1              0              0   \n",
       "7976                 0            0              0              1   \n",
       "8357                 0            0              0              1   \n",
       "8424                 0            0              0              1   \n",
       "8737                 0            0              0              1   \n",
       "8842                 0            0              0              1   \n",
       "\n",
       "      gear_Automatic  gear_Manual   price  pre_backtrans_pred  \n",
       "77                 1            0   83870        3.996071e+09  \n",
       "101                1            0   34950        5.998644e+09  \n",
       "824                0            1    8500        7.560187e+09  \n",
       "1032               1            0   35000        3.379601e+08  \n",
       "2314               1            0   99800        3.948626e+10  \n",
       "2468               1            0   86885        3.379601e+08  \n",
       "2550               1            0    9985        5.998644e+09  \n",
       "3623               1            0   39925        7.201592e+09  \n",
       "3684               1            0   45555        6.188076e+09  \n",
       "4405               1            0   33994        7.184330e+09  \n",
       "5657               1            0   29950        3.379601e+08  \n",
       "5768               1            0  175470        3.131556e+09  \n",
       "6280               1            0   52490        6.188076e+09  \n",
       "6591               0            1   17300        6.188076e+09  \n",
       "6602               0            1    1190        1.721461e+09  \n",
       "6637               1            0    9900        1.609189e+09  \n",
       "7748               0            1    7480        7.560187e+09  \n",
       "7976               1            0   10900        6.466283e+06  \n",
       "8357               0            1   94900        1.463901e+10  \n",
       "8424               1            0   44930        7.201592e+09  \n",
       "8737               0            1    3400        6.316963e+09  \n",
       "8842               0            1   55900        3.722491e+09  \n",
       "\n",
       "[22 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_before = lr_pred_df.index\n",
    "rows_before = lr_pred_df.shape[0]\n",
    "\n",
    "lr_pred_df = lr_pred_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "index_after = lr_pred_df.index\n",
    "rows_after = lr_pred_df.shape[0]\n",
    "\n",
    "removed_indices = index_before.difference(index_after)\n",
    "removed_rows = rows_before - rows_after\n",
    "percent_removed = (removed_rows / rows_before) * 100\n",
    "\n",
    "removed_rows_X_test = X_test.iloc[removed_indices]\n",
    "removed_rows_y_test = y_test.iloc[removed_indices]\n",
    "removed_rows_df = pd.concat([removed_rows_X_test, removed_rows_y_test], axis=1)\n",
    "removed_rows_df['pre_backtrans_pred'] = lr_pred.flatten()[removed_indices]\n",
    "filtered_removed_rows_df = removed_rows_df.loc[:, (removed_rows_df != 0).any()]\n",
    "\n",
    "print('Rows before removing NaNs and Infs:', rows_before)\n",
    "print('Rows after removing NaNs and Infs:', rows_after)\n",
    "print('Number of rows removed:', removed_rows)\n",
    "print('Percentage of rows removed:', percent_removed, '%')\n",
    "\n",
    "print(\"Problematic rows in X_test and y_test:\")\n",
    "filtered_removed_rows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the linear regression model leads to extremely high predicted values for the problematic rows. Therefore, the back transformation fails, leading to infinite values. The full linear regression model therefore appears to be unsuitable. After removing the problematic rows, the evaluation metrics are calculated.  However, it should be noted that these can only be interpreted to a limited extent, as not all predictions are taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.928132</td>\n",
       "      <td>0.920122</td>\n",
       "      <td>4906.257588</td>\n",
       "      <td>15.906764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model        r2    r2_adj         rmse    seconds\n",
       "0    lr  0.928132  0.920122  4906.257588  15.906764"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r2 = r2_score(lr_pred_df['y_test'], lr_pred_df['pred'])\n",
    "lr_r2_adj = 1 - (1 - lr_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "lr_rmse = np.sqrt(mean_squared_error(lr_pred_df['y_test'], lr_pred_df['pred']))\n",
    "lr_seconds = lr_delta.seconds + lr_delta.microseconds/1E6\n",
    "\n",
    "lr_evaluation = pd.DataFrame({\n",
    "    'model': ['lr'],\n",
    "    'r2': [lr_r2],\n",
    "    'r2_adj': [lr_r2_adj],\n",
    "    'rmse': [lr_rmse],\n",
    "    'seconds': [lr_seconds]\n",
    "})\n",
    "\n",
    "lr_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model, model predictions and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_model, '../models/models/lr_model.pkl')\n",
    "lr_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"lr_evaluation.csv\"), index=False)\n",
    "lr_res = pd.DataFrame(lr_pred)\n",
    "lr_res.index = X_test.index\n",
    "lr_res.columns = [\"prediction\"]\n",
    "lr_res.to_csv(\"../models/predictions/lr_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"alpha\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 19:04:18,003] A new study created in memory with name: no-name-3a79e641-7114-40c5-878d-6b257df9fb34\n",
      "[I 2024-02-09 19:04:28,295] Trial 0 finished with value: 0.7013207160161288 and parameters: {'alpha': 10243321.458660385}. Best is trial 0 with value: 0.7013207160161288.\n",
      "[I 2024-02-09 19:08:33,305] Trial 1 finished with value: 0.16394805195471082 and parameters: {'alpha': 5.96865180528638e-07}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:38,564] Trial 2 finished with value: 0.7013207160161288 and parameters: {'alpha': 401158.3420221274}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:43,155] Trial 3 finished with value: 0.7013207160161288 and parameters: {'alpha': 836.8044150727266}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:47,370] Trial 4 finished with value: 0.7013207160161288 and parameters: {'alpha': 9.170761659151827}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:51,996] Trial 5 finished with value: 0.7013207160161288 and parameters: {'alpha': 19802190.19690238}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:57,308] Trial 6 finished with value: 0.7013207160161288 and parameters: {'alpha': 0.7737208697265361}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:09:02,472] Trial 7 finished with value: 0.7013207160161288 and parameters: {'alpha': 583869975.9426675}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:09:07,763] Trial 8 finished with value: 0.7013207160161288 and parameters: {'alpha': 16.59259553215712}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:13:27,760] Trial 9 finished with value: 0.16389049879721082 and parameters: {'alpha': 4.189615204360501e-06}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:18:02,866] Trial 10 finished with value: 0.1642869282150733 and parameters: {'alpha': 1.5559380994842274e-09}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:04,134] Trial 11 finished with value: 0.16392637328019716 and parameters: {'alpha': 8.293296603310652e-07}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:33,279] Trial 12 finished with value: 0.18119144097822065 and parameters: {'alpha': 0.0001176924519363625}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:41,408] Trial 13 finished with value: 0.19476144323139022 and parameters: {'alpha': 0.00040154110507913105}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:27:03,745] Trial 14 finished with value: 0.16428741892204218 and parameters: {'alpha': 1.3738759021723526e-09}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:27:25,977] Trial 15 finished with value: 0.18270563257386369 and parameters: {'alpha': 0.00013193783928244787}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:31:27,367] Trial 16 finished with value: 0.16388752627560566 and parameters: {'alpha': 1.9516900194665794e-06}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:31:33,200] Trial 17 finished with value: 0.36277456810536285 and parameters: {'alpha': 0.023835213172484666}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:35:34,949] Trial 18 finished with value: 0.16396417131572627 and parameters: {'alpha': 4.4734639418797396e-07}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:35:41,088] Trial 19 finished with value: 0.2325967385786135 and parameters: {'alpha': 0.0049580607036358495}. Best is trial 16 with value: 0.16388752627560566.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.9516900194665794e-06}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coarse_study = optuna.create_study(direction='minimize')\n",
    "lasso_coarse_study.optimize(lasso_coarse_objective, n_trials=20)\n",
    "lasso_coarse_best_params = lasso_coarse_study.best_params\n",
    "lasso_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 22:05:22,906] A new study created in memory with name: no-name-63e3e229-f876-40ed-8234-230ff6f3fbd4\n",
      "[I 2024-02-09 22:09:08,328] Trial 0 finished with value: 0.16387247936991217 and parameters: {'alpha': 3.3649281346240794e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:12:05,381] Trial 1 finished with value: 0.1639890023075982 and parameters: {'alpha': 3.50098099799282e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:15:26,831] Trial 2 finished with value: 0.163960839806155 and parameters: {'alpha': 5.928976887895147e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:18:52,154] Trial 3 finished with value: 0.16397385111604876 and parameters: {'alpha': 6.14406310830036e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:22:16,639] Trial 4 finished with value: 0.1639914131708431 and parameters: {'alpha': 3.420306904942853e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:25:35,740] Trial 5 finished with value: 0.16389030004894473 and parameters: {'alpha': 1.7282593114263626e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:28:27,564] Trial 6 finished with value: 0.16410428364448676 and parameters: {'alpha': 1.218444651509368e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:32:26,535] Trial 7 finished with value: 0.16391171948516461 and parameters: {'alpha': 1.1433959832426737e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:36:52,828] Trial 8 finished with value: 0.1640306902358677 and parameters: {'alpha': 2.4066228261469425e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:41:08,549] Trial 9 finished with value: 0.1639714224820903 and parameters: {'alpha': 4.184258984029763e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:44:42,454] Trial 10 finished with value: 0.1638721501595497 and parameters: {'alpha': 2.6013635911554013e-06}. Best is trial 10 with value: 0.1638721501595497.\n",
      "[I 2024-02-09 22:47:52,229] Trial 11 finished with value: 0.1638733838028849 and parameters: {'alpha': 2.5045966591931192e-06}. Best is trial 10 with value: 0.1638721501595497.\n",
      "[I 2024-02-09 22:51:08,058] Trial 12 finished with value: 0.1638704204936376 and parameters: {'alpha': 3.1599970196135527e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 22:54:12,961] Trial 13 finished with value: 0.1642964438463651 and parameters: {'alpha': 9.432099132371166e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 22:57:04,913] Trial 14 finished with value: 0.1639171660351192 and parameters: {'alpha': 1.000406276073766e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:00:16,670] Trial 15 finished with value: 0.1638716458846639 and parameters: {'alpha': 3.3134566972147136e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:03:31,246] Trial 16 finished with value: 0.16391227454344606 and parameters: {'alpha': 4.890587954669088e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:06:42,724] Trial 17 finished with value: 0.16388997548880066 and parameters: {'alpha': 1.660075376658924e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:09:58,191] Trial 18 finished with value: 0.16393612069400657 and parameters: {'alpha': 7.020916880724997e-07}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:13:05,571] Trial 19 finished with value: 0.1638863020391366 and parameters: {'alpha': 4.007489351379599e-06}. Best is trial 12 with value: 0.1638704204936376.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 3.1599970196135527e-06}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_fine_study = optuna.create_study(direction='minimize')\n",
    "lasso_fine_study.optimize(lasso_fine_objective, n_trials=20)\n",
    "lasso_fine_best_params = lasso_fine_study.best_params\n",
    "lasso_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 3.1599970196135527e-06."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+01, tolerance: 1.813e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=lasso_fine_best_params['alpha'])\n",
    "lasso_start = datetime.now()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_stop = datetime.now()\n",
    "lasso_delta = lasso_stop - lasso_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lasso</td>\n",
       "      <td>0.949303</td>\n",
       "      <td>0.943652</td>\n",
       "      <td>4152.140941</td>\n",
       "      <td>53.182399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse    seconds\n",
       "0  lasso  0.949303  0.943652  4152.140941  53.182399"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pred_inverse = np.expm1(lasso_pred)\n",
    "\n",
    "lasso_r2 = r2_score(y_test, lasso_pred_inverse)\n",
    "lasso_r2_adj = 1 - (1 - lasso_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso_pred_inverse))\n",
    "lasso_seconds = lasso_delta.seconds + lasso_delta.microseconds/1E6\n",
    "\n",
    "lasso_evaluation = pd.DataFrame({\n",
    "    'model': ['lasso'],\n",
    "    'r2': [lasso_r2],\n",
    "    'r2_adj': [lasso_r2_adj],\n",
    "    'rmse': [lasso_rmse],\n",
    "    'seconds': [lasso_seconds]\n",
    "})\n",
    "\n",
    "lasso_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lasso_model, '../models/models/lasso_model.pkl')\n",
    "lasso_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"lasso_evaluation.csv\"), index=False)\n",
    "lasso_res = pd.DataFrame(lasso_pred)\n",
    "lasso_res.index = X_test.index\n",
    "lasso_res.columns = [\"prediction\"]\n",
    "lasso_res.to_csv(\"../models/predictions/lasso_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the ridge hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"alpha\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:36:40,634] A new study created in memory with name: no-name-980e92ef-e28b-4d0c-9bce-ce0fa5a6cbc8\n",
      "[I 2024-02-09 23:36:50,021] Trial 0 finished with value: 0.16424857262649997 and parameters: {'alpha': 1.1743120410150176}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:36:55,919] Trial 1 finished with value: 0.17098125868126882 and parameters: {'alpha': 10.535200575024227}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:01,370] Trial 2 finished with value: 0.18931491451252808 and parameters: {'alpha': 49.63657417215814}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:07,791] Trial 3 finished with value: 0.6998189954419571 and parameters: {'alpha': 3193783.064577547}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:15,744] Trial 4 finished with value: 0.418584998793132 and parameters: {'alpha': 3237.982475531299}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:21,331] Trial 5 finished with value: 0.16423515997889412 and parameters: {'alpha': 0.0011326405463555165}. Best is trial 5 with value: 0.16423515997889412.\n",
      "[I 2024-02-09 23:37:27,549] Trial 6 finished with value: 0.1642526386536567 and parameters: {'alpha': 7.429034513348599e-08}. Best is trial 5 with value: 0.16423515997889412.\n",
      "[I 2024-02-09 23:37:34,372] Trial 7 finished with value: 0.16392721865235738 and parameters: {'alpha': 0.19240665124910455}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:40,883] Trial 8 finished with value: 0.1642524203400879 and parameters: {'alpha': 1.3382682436137682e-05}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:48,372] Trial 9 finished with value: 0.3310280296650617 and parameters: {'alpha': 950.7938589978701}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:54,213] Trial 10 finished with value: 0.7012831868065359 and parameters: {'alpha': 128446984.1820619}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:02,379] Trial 11 finished with value: 0.16424410662714894 and parameters: {'alpha': 0.0005335539293584385}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:09,669] Trial 12 finished with value: 0.1642179117599708 and parameters: {'alpha': 0.002420256368322732}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:17,090] Trial 13 finished with value: 0.1642236633579564 and parameters: {'alpha': 0.0019697676693886247}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:23,797] Trial 14 finished with value: 0.16425256409070527 and parameters: {'alpha': 1.7487675638354417e-09}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:30,444] Trial 15 finished with value: 0.16408842621761263 and parameters: {'alpha': 0.025092035966330875}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:36,664] Trial 16 finished with value: 0.16393077952482277 and parameters: {'alpha': 0.18400424820661812}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:42,263] Trial 17 finished with value: 0.6516804304298842 and parameters: {'alpha': 80685.02833280104}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:48,678] Trial 18 finished with value: 0.16425257782827488 and parameters: {'alpha': 3.84440080229112e-06}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:54,365] Trial 19 finished with value: 0.16389690495513123 and parameters: {'alpha': 0.350978657363417}. Best is trial 19 with value: 0.16389690495513123.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.350978657363417}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coarse_study = optuna.create_study(direction='minimize')\n",
    "ridge_coarse_study.optimize(ridge_coarse_objective, n_trials=20)\n",
    "ridge_coarse_best_params = ridge_coarse_study.best_params\n",
    "ridge_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-1 to 10^0, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-1, 1e0, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:45:01,863] A new study created in memory with name: no-name-91b9b771-80b7-49b9-80a7-d1fbd13061b2\n",
      "[I 2024-02-09 23:45:14,934] Trial 0 finished with value: 0.16400502975907394 and parameters: {'alpha': 0.7560482810597207}. Best is trial 0 with value: 0.16400502975907394.\n",
      "[I 2024-02-09 23:45:22,776] Trial 1 finished with value: 0.16391336117257108 and parameters: {'alpha': 0.4982289691237173}. Best is trial 1 with value: 0.16391336117257108.\n",
      "[I 2024-02-09 23:45:30,822] Trial 2 finished with value: 0.16389780865442807 and parameters: {'alpha': 0.38887340984488644}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:36,991] Trial 3 finished with value: 0.16395869677401717 and parameters: {'alpha': 0.13233143481954387}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:44,444] Trial 4 finished with value: 0.16405648400067147 and parameters: {'alpha': 0.8585941195554095}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:52,589] Trial 5 finished with value: 0.16391635792561252 and parameters: {'alpha': 0.51139079319983}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:59,183] Trial 6 finished with value: 0.16396780912400896 and parameters: {'alpha': 0.11911485905324662}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:05,564] Trial 7 finished with value: 0.16390734804538704 and parameters: {'alpha': 0.4680901106966353}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:11,013] Trial 8 finished with value: 0.16400470884976642 and parameters: {'alpha': 0.7553616900580229}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:17,070] Trial 9 finished with value: 0.16405325075217167 and parameters: {'alpha': 0.8525143787247235}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:22,905] Trial 10 finished with value: 0.16391928040257817 and parameters: {'alpha': 0.21359960912263237}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:28,892] Trial 11 finished with value: 0.16389820786328974 and parameters: {'alpha': 0.31969121104570075}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:35,402] Trial 12 finished with value: 0.1639023192823017 and parameters: {'alpha': 0.2832853467432849}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:41,044] Trial 13 finished with value: 0.16390086966129563 and parameters: {'alpha': 0.2934759493059888}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:47,281] Trial 14 finished with value: 0.16393161201813272 and parameters: {'alpha': 0.1821199978310215}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:53,117] Trial 15 finished with value: 0.16389749915406876 and parameters: {'alpha': 0.38295643925989914}. Best is trial 15 with value: 0.16389749915406876.\n",
      "[I 2024-02-09 23:46:58,844] Trial 16 finished with value: 0.16390755296290732 and parameters: {'alpha': 0.46922871536559546}. Best is trial 15 with value: 0.16389749915406876.\n",
      "[I 2024-02-09 23:47:04,814] Trial 17 finished with value: 0.16389692410089277 and parameters: {'alpha': 0.36415511361529757}. Best is trial 17 with value: 0.16389692410089277.\n",
      "[I 2024-02-09 23:47:10,641] Trial 18 finished with value: 0.16392000223252576 and parameters: {'alpha': 0.21150234764808162}. Best is trial 17 with value: 0.16389692410089277.\n",
      "[I 2024-02-09 23:47:16,674] Trial 19 finished with value: 0.16395667946604914 and parameters: {'alpha': 0.6418344458281925}. Best is trial 17 with value: 0.16389692410089277.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.36415511361529757}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_fine_study = optuna.create_study(direction='minimize')\n",
    "ridge_fine_study.optimize(ridge_fine_objective, n_trials=20)\n",
    "ridge_fine_best_params = ridge_fine_study.best_params\n",
    "ridge_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 0.36415511361529757."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ridge model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=ridge_fine_best_params['alpha'])\n",
    "ridge_start = datetime.now()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_stop = datetime.now()\n",
    "ridge_delta = ridge_stop - ridge_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.933437</td>\n",
       "      <td>4512.857727</td>\n",
       "      <td>1.733712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse   seconds\n",
       "0  ridge  0.940112  0.933437  4512.857727  1.733712"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred_inverse = np.expm1(ridge_pred)\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_pred_inverse)\n",
    "ridge_r2_adj = 1 - (1 - ridge_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred_inverse))\n",
    "ridge_seconds = ridge_delta.seconds + ridge_delta.microseconds/1E6\n",
    "\n",
    "ridge_evaluation = pd.DataFrame({\n",
    "    'model': ['ridge'],\n",
    "    'r2': [ridge_r2],\n",
    "    'r2_adj': [ridge_r2_adj],\n",
    "    'rmse': [ridge_rmse],\n",
    "    'seconds': [ridge_seconds]\n",
    "})\n",
    "\n",
    "ridge_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ridge_model, '../models/models/ridge_model.pkl')\n",
    "ridge_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"ridge_evaluation.csv\"), index=False)\n",
    "ridge_res = pd.DataFrame(ridge_pred)\n",
    "ridge_res.index = X_test.index\n",
    "ridge_res.columns = [\"prediction\"]\n",
    "ridge_res.to_csv(\"../models/predictions/ridge_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the elastic net hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameters \"alpha\" and the \"l1 ratio\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "    elasticnet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(elasticnet, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:56:44,342] A new study created in memory with name: no-name-6bcc7919-3a04-4ee0-9f52-ca1229989486\n",
      "[I 2024-02-09 23:56:51,473] Trial 0 finished with value: 0.7013207160161288 and parameters: {'alpha': 73.05249792172569, 'l1_ratio': 0.48929492242600703}. Best is trial 0 with value: 0.7013207160161288.\n",
      "[I 2024-02-10 00:00:09,481] Trial 1 finished with value: 0.16428393249434645 and parameters: {'alpha': 3.698522250451831e-09, 'l1_ratio': 0.8038315597375395}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:00:13,032] Trial 2 finished with value: 0.7013207160161288 and parameters: {'alpha': 1.5506251802243947, 'l1_ratio': 0.7408186330293501}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:00:20,307] Trial 3 finished with value: 0.19518038543879007 and parameters: {'alpha': 0.0009063432259673031, 'l1_ratio': 0.3853263311447038}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:03:35,356] Trial 4 finished with value: 0.1641418528787575 and parameters: {'alpha': 1.953388364083622e-05, 'l1_ratio': 0.24998298340864977}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:03:39,818] Trial 5 finished with value: 0.6762410378123718 and parameters: {'alpha': 0.2588615293534744, 'l1_ratio': 0.6401614670553343}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:03:43,337] Trial 6 finished with value: 0.7013207160161288 and parameters: {'alpha': 461506459.78979677, 'l1_ratio': 0.2917224538861707}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:04:05,417] Trial 7 finished with value: 0.17457499374843988 and parameters: {'alpha': 0.00011669544236095001, 'l1_ratio': 0.5469958637591138}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:04:09,454] Trial 8 finished with value: 0.7013207160161288 and parameters: {'alpha': 46.88583042289867, 'l1_ratio': 0.9387840720063189}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:07:08,238] Trial 9 finished with value: 0.16428284349749916 and parameters: {'alpha': 4.436459353150842e-09, 'l1_ratio': 0.829349968956481}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:07:11,831] Trial 10 finished with value: 0.7013207160161288 and parameters: {'alpha': 419374.1610050739, 'l1_ratio': 0.0591208092504627}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:10:26,406] Trial 11 finished with value: 0.16429010552054119 and parameters: {'alpha': 1.2851391740585937e-09, 'l1_ratio': 0.16591110027542266}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:13:32,373] Trial 12 finished with value: 0.163898912310572 and parameters: {'alpha': 2.430224145742283e-06, 'l1_ratio': 0.26693419316393463}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:16:26,724] Trial 13 finished with value: 0.16482331734295858 and parameters: {'alpha': 3.3972548471724546e-05, 'l1_ratio': 0.24422576212520347}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:19:44,589] Trial 14 finished with value: 0.16401969010551784 and parameters: {'alpha': 1.9202343558372625e-06, 'l1_ratio': 0.016463116107983122}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:22:38,035] Trial 15 finished with value: 0.16398825103045694 and parameters: {'alpha': 2.940995746691278e-06, 'l1_ratio': 0.0003477535378410765}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:25:47,918] Trial 16 finished with value: 0.16414102352827914 and parameters: {'alpha': 3.924890203763333e-07, 'l1_ratio': 0.13365013465467537}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:25:57,167] Trial 17 finished with value: 0.24972103952583052 and parameters: {'alpha': 0.005815297145431985, 'l1_ratio': 0.4316055634986944}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:28:59,431] Trial 18 finished with value: 0.1642940794652116 and parameters: {'alpha': 2.149269812074249e-07, 'l1_ratio': 0.005606785602731035}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:29:04,861] Trial 19 finished with value: 0.4055965574201214 and parameters: {'alpha': 0.041656007753575044, 'l1_ratio': 0.3636937379329225}. Best is trial 12 with value: 0.163898912310572.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.430224145742283e-06, 'l1_ratio': 0.26693419316393463}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_coarse_study = optuna.create_study(direction='minimize')\n",
    "elasticnet_coarse_study.optimize(elasticnet_coarse_objective, n_trials=20)\n",
    "elasticnet_coarse_best_params = elasticnet_coarse_study.best_params\n",
    "elasticnet_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6 and l1 ratio 10^-1 to 10^0, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.1, 1)\n",
    "    elasticnet = ElasticNet(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(elasticnet, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 00:56:58,441] A new study created in memory with name: no-name-f942f13e-b614-4983-9dcf-80893e13c93e\n",
      "[I 2024-02-10 01:00:24,000] Trial 0 finished with value: 0.16387115187660722 and parameters: {'alpha': 6.853742464288298e-06, 'l1_ratio': 0.9444272520565056}. Best is trial 0 with value: 0.16387115187660722.\n",
      "[I 2024-02-10 01:03:32,391] Trial 1 finished with value: 0.1638834862773019 and parameters: {'alpha': 2.103684115749e-06, 'l1_ratio': 0.39341000050517383}. Best is trial 0 with value: 0.16387115187660722.\n",
      "[I 2024-02-10 01:06:39,545] Trial 2 finished with value: 0.16406330363241867 and parameters: {'alpha': 3.0227541744550315e-07, 'l1_ratio': 0.4201850685184251}. Best is trial 0 with value: 0.16387115187660722.\n",
      "[I 2024-02-10 01:09:40,722] Trial 3 finished with value: 0.1639364295174587 and parameters: {'alpha': 1.0178618975763246e-06, 'l1_ratio': 0.6600220041219447}. Best is trial 0 with value: 0.16387115187660722.\n",
      "[I 2024-02-10 01:12:54,682] Trial 4 finished with value: 0.16384654268812465 and parameters: {'alpha': 5.3691820755665825e-06, 'l1_ratio': 0.8158284397514489}. Best is trial 4 with value: 0.16384654268812465.\n",
      "[I 2024-02-10 01:16:11,163] Trial 5 finished with value: 0.1638449999846934 and parameters: {'alpha': 4.194742291944115e-06, 'l1_ratio': 0.7115752854023589}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:19:26,026] Trial 6 finished with value: 0.16399719744344748 and parameters: {'alpha': 5.320786314603358e-07, 'l1_ratio': 0.9091527303660141}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:22:23,136] Trial 7 finished with value: 0.16415391335002233 and parameters: {'alpha': 1.4288668388411278e-07, 'l1_ratio': 0.8820007575967708}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:25:11,558] Trial 8 finished with value: 0.16413979194223066 and parameters: {'alpha': 1.622129346247033e-07, 'l1_ratio': 0.12108834393903502}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:28:25,522] Trial 9 finished with value: 0.16384545990048208 and parameters: {'alpha': 4.112763689166889e-06, 'l1_ratio': 0.9138878757704035}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:31:29,003] Trial 10 finished with value: 0.16389712602131698 and parameters: {'alpha': 1.7859065316561073e-06, 'l1_ratio': 0.6665320258784126}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:34:39,900] Trial 11 finished with value: 0.163852945072531 and parameters: {'alpha': 3.290080121585973e-06, 'l1_ratio': 0.7084205942715022}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:37:55,252] Trial 12 finished with value: 0.16396297517460962 and parameters: {'alpha': 9.728925934298184e-06, 'l1_ratio': 0.5066223343814745}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:40:52,490] Trial 13 finished with value: 0.163849362751545 and parameters: {'alpha': 3.548167801215789e-06, 'l1_ratio': 0.9894383395952994}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:44:01,159] Trial 14 finished with value: 0.16393332223546214 and parameters: {'alpha': 1.1299548363609193e-06, 'l1_ratio': 0.7745353325350066}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:47:25,333] Trial 15 finished with value: 0.1638501274332238 and parameters: {'alpha': 3.47818028690636e-06, 'l1_ratio': 0.2232755469284503}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:50:30,188] Trial 16 finished with value: 0.16389709203060662 and parameters: {'alpha': 1.7870074384286445e-06, 'l1_ratio': 0.5202902723584681}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:53:41,211] Trial 17 finished with value: 0.1639756462674338 and parameters: {'alpha': 6.322299501261505e-07, 'l1_ratio': 0.7933943763525777}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 01:56:46,635] Trial 18 finished with value: 0.16397127576619608 and parameters: {'alpha': 9.945336059294893e-06, 'l1_ratio': 0.6162914781167482}. Best is trial 5 with value: 0.1638449999846934.\n",
      "[I 2024-02-10 02:00:01,007] Trial 19 finished with value: 0.16384428451935568 and parameters: {'alpha': 5.0130395859195585e-06, 'l1_ratio': 0.848536496932069}. Best is trial 19 with value: 0.16384428451935568.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 5.0130395859195585e-06, 'l1_ratio': 0.848536496932069}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_fine_study = optuna.create_study(direction='minimize')\n",
    "elasticnet_fine_study.optimize(elasticnet_fine_objective, n_trials=20)\n",
    "elasticnet_fine_best_params = elasticnet_fine_study.best_params\n",
    "elasticnet_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Robust Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. Huber Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3. RANSAC Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4. Theil Sen Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1. Multi-Layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Decision Trees Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.1. Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.2. Bagging Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.3. Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.4. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.6. LightGBM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.7. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.8. Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.9. Stacking Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.10. Voting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.11. Histogram-based Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Dimensionality-Reduced Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
