{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, HuberRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "import logging\n",
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\")\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train linear regression model and measure computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression() \n",
    "lr_start = datetime.now()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_stop = datetime.now()\n",
    "lr_delta = lr_stop - lr_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the log-transformation applied to the target variable y_train during data preprocessing to ensure normality and linearity, it is necessary to reverse this transformation on the predictions before assessing the model using metrics such as RMSE and R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: overflow encountered in expm1\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_test_log = np.log1p(y_test.to_numpy())\n",
    "\n",
    "lr_pred_df = pd.DataFrame({'pred': lr_pred.flatten(), 'y_test': y_test_log.flatten()})\n",
    "\n",
    "lr_pred_df['pred'] = np.expm1(lr_pred_df['pred'])\n",
    "lr_pred_df['y_test'] = np.expm1(lr_pred_df['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the back-transformation, NaNs and Infs occurred for some rows. These entries are eliminated, and the indices of the removed rows are stored to identify the observations that led to these issues. Additionally, the total count and the relative proportion of dropped rows are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before removing NaNs and Infs: 9215\n",
      "Rows after removing NaNs and Infs: 9193\n",
      "Number of rows removed: 22\n",
      "Percentage of rows removed: 0.23874118285404233 %\n",
      "Problematic rows in X_test and y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mileage</th>\n",
       "      <th>offerType</th>\n",
       "      <th>hp</th>\n",
       "      <th>year</th>\n",
       "      <th>make_Audi</th>\n",
       "      <th>make_BMW</th>\n",
       "      <th>make_Bentley</th>\n",
       "      <th>make_Corvette</th>\n",
       "      <th>make_DS</th>\n",
       "      <th>make_Fiat</th>\n",
       "      <th>...</th>\n",
       "      <th>model_S7</th>\n",
       "      <th>model_SLC 250</th>\n",
       "      <th>model_T5 Shuttle</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_Electric</th>\n",
       "      <th>fuel_Gasoline</th>\n",
       "      <th>gear_Automatic</th>\n",
       "      <th>gear_Manual</th>\n",
       "      <th>price</th>\n",
       "      <th>pre_backtrans_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.139248</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83870</td>\n",
       "      <td>3.996071e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34950</td>\n",
       "      <td>5.998644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.339380</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8500</td>\n",
       "      <td>7.560187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>0.283372</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.678830</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>0.403326</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.810958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99800</td>\n",
       "      <td>3.948626e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>0.126833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.770530</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86885</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>0.554074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.493344</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9985</td>\n",
       "      <td>5.998644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>0.398366</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39925</td>\n",
       "      <td>7.201592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>0.208001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45555</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>0.020801</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.409779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33994</td>\n",
       "      <td>7.184330e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>0.377976</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29950</td>\n",
       "      <td>3.379601e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>0.110521</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.854646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175470</td>\n",
       "      <td>3.131556e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>0.200830</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52490</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>0.608220</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.448622</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17300</td>\n",
       "      <td>6.188076e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>0.449051</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.373640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1190</td>\n",
       "      <td>1.721461e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>0.332922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.398820</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9900</td>\n",
       "      <td>1.609189e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7748</th>\n",
       "      <td>0.442519</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.361263</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7480</td>\n",
       "      <td>7.560187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>0.445133</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.520298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10900</td>\n",
       "      <td>6.466283e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8357</th>\n",
       "      <td>0.244699</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.886967</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94900</td>\n",
       "      <td>1.463901e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8424</th>\n",
       "      <td>0.374173</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.766887</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44930</td>\n",
       "      <td>7.201592e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8737</th>\n",
       "      <td>0.483186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.327765</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3400</td>\n",
       "      <td>6.316963e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842</th>\n",
       "      <td>0.075173</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.305522</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55900</td>\n",
       "      <td>3.722491e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mileage  offerType        hp  year  make_Audi  make_BMW  make_Bentley  \\\n",
       "77    0.139248       0.50  0.538058   1.0          0         0             0   \n",
       "101   0.300000       0.00  0.732819   0.6          0         0             0   \n",
       "824   0.406800       0.00  0.339380   0.5          0         0             0   \n",
       "1032  0.283372       0.00  0.678830   0.7          0         1             0   \n",
       "2314  0.403326       0.00  0.810958   0.0          0         0             1   \n",
       "2468  0.126833       0.00  0.770530   0.8          0         0             0   \n",
       "2550  0.554074       0.00  0.493344   0.4          0         0             0   \n",
       "3623  0.398366       0.00  0.744444   0.3          1         0             0   \n",
       "3684  0.208001       0.50  0.538058   1.0          0         0             0   \n",
       "4405  0.020801       0.75  0.409779   1.0          0         0             0   \n",
       "5657  0.377976       0.00  0.538058   0.5          0         0             0   \n",
       "5768  0.110521       0.00  0.854646   1.0          0         0             0   \n",
       "6280  0.200830       0.00  0.538058   1.0          0         0             0   \n",
       "6591  0.608220       0.00  0.448622   0.2          0         0             0   \n",
       "6602  0.449051       0.00  0.373640   0.0          0         0             0   \n",
       "6637  0.332922       0.00  0.398820   0.2          0         0             0   \n",
       "7748  0.442519       0.00  0.361263   0.3          0         0             0   \n",
       "7976  0.445133       0.00  0.520298   0.0          0         1             0   \n",
       "8357  0.244699       0.00  0.886967   0.7          0         0             0   \n",
       "8424  0.374173       0.00  0.766887   0.5          1         0             0   \n",
       "8737  0.483186       0.00  0.327765   0.1          0         0             0   \n",
       "8842  0.075173       0.00  0.305522   0.8          0         0             0   \n",
       "\n",
       "      make_Corvette  make_DS  make_Fiat  ...  model_S7  model_SLC 250  \\\n",
       "77                0        0          0  ...         0              0   \n",
       "101               0        0          0  ...         0              0   \n",
       "824               0        1          0  ...         0              0   \n",
       "1032              0        0          0  ...         0              0   \n",
       "2314              0        0          0  ...         0              0   \n",
       "2468              0        0          0  ...         0              0   \n",
       "2550              0        0          0  ...         0              0   \n",
       "3623              0        0          0  ...         1              0   \n",
       "3684              0        0          0  ...         0              0   \n",
       "4405              0        0          1  ...         0              0   \n",
       "5657              0        0          0  ...         0              1   \n",
       "5768              0        0          0  ...         0              0   \n",
       "6280              0        0          0  ...         0              0   \n",
       "6591              0        0          0  ...         0              0   \n",
       "6602              0        0          0  ...         0              0   \n",
       "6637              0        0          0  ...         0              0   \n",
       "7748              0        1          0  ...         0              0   \n",
       "7976              0        0          0  ...         0              0   \n",
       "8357              1        0          0  ...         0              0   \n",
       "8424              0        0          0  ...         1              0   \n",
       "8737              0        0          1  ...         0              0   \n",
       "8842              0        0          0  ...         0              0   \n",
       "\n",
       "      model_T5 Shuttle  fuel_Diesel  fuel_Electric  fuel_Gasoline  \\\n",
       "77                   0            0              1              0   \n",
       "101                  0            0              0              1   \n",
       "824                  0            0              0              1   \n",
       "1032                 0            0              0              1   \n",
       "2314                 0            0              0              1   \n",
       "2468                 0            0              0              1   \n",
       "2550                 0            1              0              0   \n",
       "3623                 0            0              0              1   \n",
       "3684                 0            0              1              0   \n",
       "4405                 0            0              1              0   \n",
       "5657                 0            1              0              0   \n",
       "5768                 0            0              0              1   \n",
       "6280                 0            0              1              0   \n",
       "6591                 1            1              0              0   \n",
       "6602                 0            0              0              1   \n",
       "6637                 0            1              0              0   \n",
       "7748                 0            1              0              0   \n",
       "7976                 0            0              0              1   \n",
       "8357                 0            0              0              1   \n",
       "8424                 0            0              0              1   \n",
       "8737                 0            0              0              1   \n",
       "8842                 0            0              0              1   \n",
       "\n",
       "      gear_Automatic  gear_Manual   price  pre_backtrans_pred  \n",
       "77                 1            0   83870        3.996071e+09  \n",
       "101                1            0   34950        5.998644e+09  \n",
       "824                0            1    8500        7.560187e+09  \n",
       "1032               1            0   35000        3.379601e+08  \n",
       "2314               1            0   99800        3.948626e+10  \n",
       "2468               1            0   86885        3.379601e+08  \n",
       "2550               1            0    9985        5.998644e+09  \n",
       "3623               1            0   39925        7.201592e+09  \n",
       "3684               1            0   45555        6.188076e+09  \n",
       "4405               1            0   33994        7.184330e+09  \n",
       "5657               1            0   29950        3.379601e+08  \n",
       "5768               1            0  175470        3.131556e+09  \n",
       "6280               1            0   52490        6.188076e+09  \n",
       "6591               0            1   17300        6.188076e+09  \n",
       "6602               0            1    1190        1.721461e+09  \n",
       "6637               1            0    9900        1.609189e+09  \n",
       "7748               0            1    7480        7.560187e+09  \n",
       "7976               1            0   10900        6.466283e+06  \n",
       "8357               0            1   94900        1.463901e+10  \n",
       "8424               1            0   44930        7.201592e+09  \n",
       "8737               0            1    3400        6.316963e+09  \n",
       "8842               0            1   55900        3.722491e+09  \n",
       "\n",
       "[22 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_before = lr_pred_df.index\n",
    "rows_before = lr_pred_df.shape[0]\n",
    "\n",
    "lr_pred_df = lr_pred_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "index_after = lr_pred_df.index\n",
    "rows_after = lr_pred_df.shape[0]\n",
    "\n",
    "removed_indices = index_before.difference(index_after)\n",
    "removed_rows = rows_before - rows_after\n",
    "percent_removed = (removed_rows / rows_before) * 100\n",
    "\n",
    "removed_rows_X_test = X_test.iloc[removed_indices]\n",
    "removed_rows_y_test = y_test.iloc[removed_indices]\n",
    "removed_rows_df = pd.concat([removed_rows_X_test, removed_rows_y_test], axis=1)\n",
    "removed_rows_df['pre_backtrans_pred'] = lr_pred.flatten()[removed_indices]\n",
    "filtered_removed_rows_df = removed_rows_df.loc[:, (removed_rows_df != 0).any()]\n",
    "\n",
    "print('Rows before removing NaNs and Infs:', rows_before)\n",
    "print('Rows after removing NaNs and Infs:', rows_after)\n",
    "print('Number of rows removed:', removed_rows)\n",
    "print('Percentage of rows removed:', percent_removed, '%')\n",
    "\n",
    "print(\"Problematic rows in X_test and y_test:\")\n",
    "filtered_removed_rows_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the linear regression model leads to extremely high predicted values for the problematic rows. Therefore, the back transformation fails, leading to infinite values. The full linear regression model therefore appears to be unsuitable. After removing the problematic rows, the evaluation metrics are calculated.  However, it should be noted that these can only be interpreted to a limited extent, as not all predictions are taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.928132</td>\n",
       "      <td>0.920122</td>\n",
       "      <td>4906.257588</td>\n",
       "      <td>15.906764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model        r2    r2_adj         rmse    seconds\n",
       "0    lr  0.928132  0.920122  4906.257588  15.906764"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r2 = r2_score(lr_pred_df['y_test'], lr_pred_df['pred'])\n",
    "lr_r2_adj = 1 - (1 - lr_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "lr_rmse = np.sqrt(mean_squared_error(lr_pred_df['y_test'], lr_pred_df['pred']))\n",
    "lr_seconds = lr_delta.seconds + lr_delta.microseconds/1E6\n",
    "\n",
    "lr_evaluation = pd.DataFrame({\n",
    "    'model': ['lr'],\n",
    "    'r2': [lr_r2],\n",
    "    'r2_adj': [lr_r2_adj],\n",
    "    'rmse': [lr_rmse],\n",
    "    'seconds': [lr_seconds]\n",
    "})\n",
    "\n",
    "lr_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model, model predictions and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_model, '../models/models/lr_model.pkl')\n",
    "lr_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"lr_evaluation.csv\"), index=False)\n",
    "lr_res = pd.DataFrame(lr_pred)\n",
    "lr_res.index = X_test.index\n",
    "lr_res.columns = [\"prediction\"]\n",
    "lr_res.to_csv(\"../models/predictions/lr_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"alpha\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 19:04:18,003] A new study created in memory with name: no-name-3a79e641-7114-40c5-878d-6b257df9fb34\n",
      "[I 2024-02-09 19:04:28,295] Trial 0 finished with value: 0.7013207160161288 and parameters: {'alpha': 10243321.458660385}. Best is trial 0 with value: 0.7013207160161288.\n",
      "[I 2024-02-09 19:08:33,305] Trial 1 finished with value: 0.16394805195471082 and parameters: {'alpha': 5.96865180528638e-07}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:38,564] Trial 2 finished with value: 0.7013207160161288 and parameters: {'alpha': 401158.3420221274}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:43,155] Trial 3 finished with value: 0.7013207160161288 and parameters: {'alpha': 836.8044150727266}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:47,370] Trial 4 finished with value: 0.7013207160161288 and parameters: {'alpha': 9.170761659151827}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:51,996] Trial 5 finished with value: 0.7013207160161288 and parameters: {'alpha': 19802190.19690238}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:08:57,308] Trial 6 finished with value: 0.7013207160161288 and parameters: {'alpha': 0.7737208697265361}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:09:02,472] Trial 7 finished with value: 0.7013207160161288 and parameters: {'alpha': 583869975.9426675}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:09:07,763] Trial 8 finished with value: 0.7013207160161288 and parameters: {'alpha': 16.59259553215712}. Best is trial 1 with value: 0.16394805195471082.\n",
      "[I 2024-02-09 19:13:27,760] Trial 9 finished with value: 0.16389049879721082 and parameters: {'alpha': 4.189615204360501e-06}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:18:02,866] Trial 10 finished with value: 0.1642869282150733 and parameters: {'alpha': 1.5559380994842274e-09}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:04,134] Trial 11 finished with value: 0.16392637328019716 and parameters: {'alpha': 8.293296603310652e-07}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:33,279] Trial 12 finished with value: 0.18119144097822065 and parameters: {'alpha': 0.0001176924519363625}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:22:41,408] Trial 13 finished with value: 0.19476144323139022 and parameters: {'alpha': 0.00040154110507913105}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:27:03,745] Trial 14 finished with value: 0.16428741892204218 and parameters: {'alpha': 1.3738759021723526e-09}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:27:25,977] Trial 15 finished with value: 0.18270563257386369 and parameters: {'alpha': 0.00013193783928244787}. Best is trial 9 with value: 0.16389049879721082.\n",
      "[I 2024-02-09 19:31:27,367] Trial 16 finished with value: 0.16388752627560566 and parameters: {'alpha': 1.9516900194665794e-06}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:31:33,200] Trial 17 finished with value: 0.36277456810536285 and parameters: {'alpha': 0.023835213172484666}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:35:34,949] Trial 18 finished with value: 0.16396417131572627 and parameters: {'alpha': 4.4734639418797396e-07}. Best is trial 16 with value: 0.16388752627560566.\n",
      "[I 2024-02-09 19:35:41,088] Trial 19 finished with value: 0.2325967385786135 and parameters: {'alpha': 0.0049580607036358495}. Best is trial 16 with value: 0.16388752627560566.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.9516900194665794e-06}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coarse_study = optuna.create_study(direction='minimize')\n",
    "lasso_coarse_study.optimize(lasso_coarse_objective, n_trials=20)\n",
    "lasso_coarse_best_params = lasso_coarse_study.best_params\n",
    "lasso_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(lasso, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 22:05:22,906] A new study created in memory with name: no-name-63e3e229-f876-40ed-8234-230ff6f3fbd4\n",
      "[I 2024-02-09 22:09:08,328] Trial 0 finished with value: 0.16387247936991217 and parameters: {'alpha': 3.3649281346240794e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:12:05,381] Trial 1 finished with value: 0.1639890023075982 and parameters: {'alpha': 3.50098099799282e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:15:26,831] Trial 2 finished with value: 0.163960839806155 and parameters: {'alpha': 5.928976887895147e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:18:52,154] Trial 3 finished with value: 0.16397385111604876 and parameters: {'alpha': 6.14406310830036e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:22:16,639] Trial 4 finished with value: 0.1639914131708431 and parameters: {'alpha': 3.420306904942853e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:25:35,740] Trial 5 finished with value: 0.16389030004894473 and parameters: {'alpha': 1.7282593114263626e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:28:27,564] Trial 6 finished with value: 0.16410428364448676 and parameters: {'alpha': 1.218444651509368e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:32:26,535] Trial 7 finished with value: 0.16391171948516461 and parameters: {'alpha': 1.1433959832426737e-06}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:36:52,828] Trial 8 finished with value: 0.1640306902358677 and parameters: {'alpha': 2.4066228261469425e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:41:08,549] Trial 9 finished with value: 0.1639714224820903 and parameters: {'alpha': 4.184258984029763e-07}. Best is trial 0 with value: 0.16387247936991217.\n",
      "[I 2024-02-09 22:44:42,454] Trial 10 finished with value: 0.1638721501595497 and parameters: {'alpha': 2.6013635911554013e-06}. Best is trial 10 with value: 0.1638721501595497.\n",
      "[I 2024-02-09 22:47:52,229] Trial 11 finished with value: 0.1638733838028849 and parameters: {'alpha': 2.5045966591931192e-06}. Best is trial 10 with value: 0.1638721501595497.\n",
      "[I 2024-02-09 22:51:08,058] Trial 12 finished with value: 0.1638704204936376 and parameters: {'alpha': 3.1599970196135527e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 22:54:12,961] Trial 13 finished with value: 0.1642964438463651 and parameters: {'alpha': 9.432099132371166e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 22:57:04,913] Trial 14 finished with value: 0.1639171660351192 and parameters: {'alpha': 1.000406276073766e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:00:16,670] Trial 15 finished with value: 0.1638716458846639 and parameters: {'alpha': 3.3134566972147136e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:03:31,246] Trial 16 finished with value: 0.16391227454344606 and parameters: {'alpha': 4.890587954669088e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:06:42,724] Trial 17 finished with value: 0.16388997548880066 and parameters: {'alpha': 1.660075376658924e-06}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:09:58,191] Trial 18 finished with value: 0.16393612069400657 and parameters: {'alpha': 7.020916880724997e-07}. Best is trial 12 with value: 0.1638704204936376.\n",
      "[I 2024-02-09 23:13:05,571] Trial 19 finished with value: 0.1638863020391366 and parameters: {'alpha': 4.007489351379599e-06}. Best is trial 12 with value: 0.1638704204936376.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 3.1599970196135527e-06}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_fine_study = optuna.create_study(direction='minimize')\n",
    "lasso_fine_study.optimize(lasso_fine_objective, n_trials=20)\n",
    "lasso_fine_best_params = lasso_fine_study.best_params\n",
    "lasso_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 3.1599970196135527e-06."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+01, tolerance: 1.813e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=lasso_fine_best_params['alpha'])\n",
    "lasso_start = datetime.now()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_stop = datetime.now()\n",
    "lasso_delta = lasso_stop - lasso_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lasso</td>\n",
       "      <td>0.949303</td>\n",
       "      <td>0.943652</td>\n",
       "      <td>4152.140941</td>\n",
       "      <td>53.182399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse    seconds\n",
       "0  lasso  0.949303  0.943652  4152.140941  53.182399"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pred_inverse = np.expm1(lasso_pred)\n",
    "\n",
    "lasso_r2 = r2_score(y_test, lasso_pred_inverse)\n",
    "lasso_r2_adj = 1 - (1 - lasso_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso_pred_inverse))\n",
    "lasso_seconds = lasso_delta.seconds + lasso_delta.microseconds/1E6\n",
    "\n",
    "lasso_evaluation = pd.DataFrame({\n",
    "    'model': ['lasso'],\n",
    "    'r2': [lasso_r2],\n",
    "    'r2_adj': [lasso_r2_adj],\n",
    "    'rmse': [lasso_rmse],\n",
    "    'seconds': [lasso_seconds]\n",
    "})\n",
    "\n",
    "lasso_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lasso_model, '../models/models/lasso_model.pkl')\n",
    "lasso_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"lasso_evaluation.csv\"), index=False)\n",
    "lasso_res = pd.DataFrame(lasso_pred)\n",
    "lasso_res.index = X_test.index\n",
    "lasso_res.columns = [\"prediction\"]\n",
    "lasso_res.to_csv(\"../models/predictions/lasso_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the ridge hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameter \"alpha\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:36:40,634] A new study created in memory with name: no-name-980e92ef-e28b-4d0c-9bce-ce0fa5a6cbc8\n",
      "[I 2024-02-09 23:36:50,021] Trial 0 finished with value: 0.16424857262649997 and parameters: {'alpha': 1.1743120410150176}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:36:55,919] Trial 1 finished with value: 0.17098125868126882 and parameters: {'alpha': 10.535200575024227}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:01,370] Trial 2 finished with value: 0.18931491451252808 and parameters: {'alpha': 49.63657417215814}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:07,791] Trial 3 finished with value: 0.6998189954419571 and parameters: {'alpha': 3193783.064577547}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:15,744] Trial 4 finished with value: 0.418584998793132 and parameters: {'alpha': 3237.982475531299}. Best is trial 0 with value: 0.16424857262649997.\n",
      "[I 2024-02-09 23:37:21,331] Trial 5 finished with value: 0.16423515997889412 and parameters: {'alpha': 0.0011326405463555165}. Best is trial 5 with value: 0.16423515997889412.\n",
      "[I 2024-02-09 23:37:27,549] Trial 6 finished with value: 0.1642526386536567 and parameters: {'alpha': 7.429034513348599e-08}. Best is trial 5 with value: 0.16423515997889412.\n",
      "[I 2024-02-09 23:37:34,372] Trial 7 finished with value: 0.16392721865235738 and parameters: {'alpha': 0.19240665124910455}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:40,883] Trial 8 finished with value: 0.1642524203400879 and parameters: {'alpha': 1.3382682436137682e-05}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:48,372] Trial 9 finished with value: 0.3310280296650617 and parameters: {'alpha': 950.7938589978701}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:37:54,213] Trial 10 finished with value: 0.7012831868065359 and parameters: {'alpha': 128446984.1820619}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:02,379] Trial 11 finished with value: 0.16424410662714894 and parameters: {'alpha': 0.0005335539293584385}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:09,669] Trial 12 finished with value: 0.1642179117599708 and parameters: {'alpha': 0.002420256368322732}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:17,090] Trial 13 finished with value: 0.1642236633579564 and parameters: {'alpha': 0.0019697676693886247}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:23,797] Trial 14 finished with value: 0.16425256409070527 and parameters: {'alpha': 1.7487675638354417e-09}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:30,444] Trial 15 finished with value: 0.16408842621761263 and parameters: {'alpha': 0.025092035966330875}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:36,664] Trial 16 finished with value: 0.16393077952482277 and parameters: {'alpha': 0.18400424820661812}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:42,263] Trial 17 finished with value: 0.6516804304298842 and parameters: {'alpha': 80685.02833280104}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:48,678] Trial 18 finished with value: 0.16425257782827488 and parameters: {'alpha': 3.84440080229112e-06}. Best is trial 7 with value: 0.16392721865235738.\n",
      "[I 2024-02-09 23:38:54,365] Trial 19 finished with value: 0.16389690495513123 and parameters: {'alpha': 0.350978657363417}. Best is trial 19 with value: 0.16389690495513123.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.350978657363417}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coarse_study = optuna.create_study(direction='minimize')\n",
    "ridge_coarse_study.optimize(ridge_coarse_objective, n_trials=20)\n",
    "ridge_coarse_best_params = ridge_coarse_study.best_params\n",
    "ridge_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-1 to 10^0, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-1, 1e0, log=True)\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(ridge, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:45:01,863] A new study created in memory with name: no-name-91b9b771-80b7-49b9-80a7-d1fbd13061b2\n",
      "[I 2024-02-09 23:45:14,934] Trial 0 finished with value: 0.16400502975907394 and parameters: {'alpha': 0.7560482810597207}. Best is trial 0 with value: 0.16400502975907394.\n",
      "[I 2024-02-09 23:45:22,776] Trial 1 finished with value: 0.16391336117257108 and parameters: {'alpha': 0.4982289691237173}. Best is trial 1 with value: 0.16391336117257108.\n",
      "[I 2024-02-09 23:45:30,822] Trial 2 finished with value: 0.16389780865442807 and parameters: {'alpha': 0.38887340984488644}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:36,991] Trial 3 finished with value: 0.16395869677401717 and parameters: {'alpha': 0.13233143481954387}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:44,444] Trial 4 finished with value: 0.16405648400067147 and parameters: {'alpha': 0.8585941195554095}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:52,589] Trial 5 finished with value: 0.16391635792561252 and parameters: {'alpha': 0.51139079319983}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:45:59,183] Trial 6 finished with value: 0.16396780912400896 and parameters: {'alpha': 0.11911485905324662}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:05,564] Trial 7 finished with value: 0.16390734804538704 and parameters: {'alpha': 0.4680901106966353}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:11,013] Trial 8 finished with value: 0.16400470884976642 and parameters: {'alpha': 0.7553616900580229}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:17,070] Trial 9 finished with value: 0.16405325075217167 and parameters: {'alpha': 0.8525143787247235}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:22,905] Trial 10 finished with value: 0.16391928040257817 and parameters: {'alpha': 0.21359960912263237}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:28,892] Trial 11 finished with value: 0.16389820786328974 and parameters: {'alpha': 0.31969121104570075}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:35,402] Trial 12 finished with value: 0.1639023192823017 and parameters: {'alpha': 0.2832853467432849}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:41,044] Trial 13 finished with value: 0.16390086966129563 and parameters: {'alpha': 0.2934759493059888}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:47,281] Trial 14 finished with value: 0.16393161201813272 and parameters: {'alpha': 0.1821199978310215}. Best is trial 2 with value: 0.16389780865442807.\n",
      "[I 2024-02-09 23:46:53,117] Trial 15 finished with value: 0.16389749915406876 and parameters: {'alpha': 0.38295643925989914}. Best is trial 15 with value: 0.16389749915406876.\n",
      "[I 2024-02-09 23:46:58,844] Trial 16 finished with value: 0.16390755296290732 and parameters: {'alpha': 0.46922871536559546}. Best is trial 15 with value: 0.16389749915406876.\n",
      "[I 2024-02-09 23:47:04,814] Trial 17 finished with value: 0.16389692410089277 and parameters: {'alpha': 0.36415511361529757}. Best is trial 17 with value: 0.16389692410089277.\n",
      "[I 2024-02-09 23:47:10,641] Trial 18 finished with value: 0.16392000223252576 and parameters: {'alpha': 0.21150234764808162}. Best is trial 17 with value: 0.16389692410089277.\n",
      "[I 2024-02-09 23:47:16,674] Trial 19 finished with value: 0.16395667946604914 and parameters: {'alpha': 0.6418344458281925}. Best is trial 17 with value: 0.16389692410089277.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.36415511361529757}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_fine_study = optuna.create_study(direction='minimize')\n",
    "ridge_fine_study.optimize(ridge_fine_objective, n_trials=20)\n",
    "ridge_fine_best_params = ridge_fine_study.best_params\n",
    "ridge_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 0.36415511361529757."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the ridge model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=ridge_fine_best_params['alpha'])\n",
    "ridge_start = datetime.now()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_stop = datetime.now()\n",
    "ridge_delta = ridge_stop - ridge_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.933437</td>\n",
       "      <td>4512.857727</td>\n",
       "      <td>1.733712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse   seconds\n",
       "0  ridge  0.940112  0.933437  4512.857727  1.733712"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred_inverse = np.expm1(ridge_pred)\n",
    "\n",
    "ridge_r2 = r2_score(y_test, ridge_pred_inverse)\n",
    "ridge_r2_adj = 1 - (1 - ridge_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred_inverse))\n",
    "ridge_seconds = ridge_delta.seconds + ridge_delta.microseconds/1E6\n",
    "\n",
    "ridge_evaluation = pd.DataFrame({\n",
    "    'model': ['ridge'],\n",
    "    'r2': [ridge_r2],\n",
    "    'r2_adj': [ridge_r2_adj],\n",
    "    'rmse': [ridge_rmse],\n",
    "    'seconds': [ridge_seconds]\n",
    "})\n",
    "\n",
    "ridge_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ridge_model, '../models/models/ridge_model.pkl')\n",
    "ridge_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"ridge_evaluation.csv\"), index=False)\n",
    "ridge_res = pd.DataFrame(ridge_pred)\n",
    "ridge_res.index = X_test.index\n",
    "ridge_res.columns = [\"prediction\"]\n",
    "ridge_res.to_csv(\"../models/predictions/ridge_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the elastic net hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameters \"alpha\" and the \"l1 ratio\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "    elasticnet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(elasticnet, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-09 23:56:44,342] A new study created in memory with name: no-name-6bcc7919-3a04-4ee0-9f52-ca1229989486\n",
      "[I 2024-02-09 23:56:51,473] Trial 0 finished with value: 0.7013207160161288 and parameters: {'alpha': 73.05249792172569, 'l1_ratio': 0.48929492242600703}. Best is trial 0 with value: 0.7013207160161288.\n",
      "[I 2024-02-10 00:00:09,481] Trial 1 finished with value: 0.16428393249434645 and parameters: {'alpha': 3.698522250451831e-09, 'l1_ratio': 0.8038315597375395}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:00:13,032] Trial 2 finished with value: 0.7013207160161288 and parameters: {'alpha': 1.5506251802243947, 'l1_ratio': 0.7408186330293501}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:00:20,307] Trial 3 finished with value: 0.19518038543879007 and parameters: {'alpha': 0.0009063432259673031, 'l1_ratio': 0.3853263311447038}. Best is trial 1 with value: 0.16428393249434645.\n",
      "[I 2024-02-10 00:03:35,356] Trial 4 finished with value: 0.1641418528787575 and parameters: {'alpha': 1.953388364083622e-05, 'l1_ratio': 0.24998298340864977}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:03:39,818] Trial 5 finished with value: 0.6762410378123718 and parameters: {'alpha': 0.2588615293534744, 'l1_ratio': 0.6401614670553343}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:03:43,337] Trial 6 finished with value: 0.7013207160161288 and parameters: {'alpha': 461506459.78979677, 'l1_ratio': 0.2917224538861707}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:04:05,417] Trial 7 finished with value: 0.17457499374843988 and parameters: {'alpha': 0.00011669544236095001, 'l1_ratio': 0.5469958637591138}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:04:09,454] Trial 8 finished with value: 0.7013207160161288 and parameters: {'alpha': 46.88583042289867, 'l1_ratio': 0.9387840720063189}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:07:08,238] Trial 9 finished with value: 0.16428284349749916 and parameters: {'alpha': 4.436459353150842e-09, 'l1_ratio': 0.829349968956481}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:07:11,831] Trial 10 finished with value: 0.7013207160161288 and parameters: {'alpha': 419374.1610050739, 'l1_ratio': 0.0591208092504627}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:10:26,406] Trial 11 finished with value: 0.16429010552054119 and parameters: {'alpha': 1.2851391740585937e-09, 'l1_ratio': 0.16591110027542266}. Best is trial 4 with value: 0.1641418528787575.\n",
      "[I 2024-02-10 00:13:32,373] Trial 12 finished with value: 0.163898912310572 and parameters: {'alpha': 2.430224145742283e-06, 'l1_ratio': 0.26693419316393463}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:16:26,724] Trial 13 finished with value: 0.16482331734295858 and parameters: {'alpha': 3.3972548471724546e-05, 'l1_ratio': 0.24422576212520347}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:19:44,589] Trial 14 finished with value: 0.16401969010551784 and parameters: {'alpha': 1.9202343558372625e-06, 'l1_ratio': 0.016463116107983122}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:22:38,035] Trial 15 finished with value: 0.16398825103045694 and parameters: {'alpha': 2.940995746691278e-06, 'l1_ratio': 0.0003477535378410765}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:25:47,918] Trial 16 finished with value: 0.16414102352827914 and parameters: {'alpha': 3.924890203763333e-07, 'l1_ratio': 0.13365013465467537}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:25:57,167] Trial 17 finished with value: 0.24972103952583052 and parameters: {'alpha': 0.005815297145431985, 'l1_ratio': 0.4316055634986944}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:28:59,431] Trial 18 finished with value: 0.1642940794652116 and parameters: {'alpha': 2.149269812074249e-07, 'l1_ratio': 0.005606785602731035}. Best is trial 12 with value: 0.163898912310572.\n",
      "[I 2024-02-10 00:29:04,861] Trial 19 finished with value: 0.4055965574201214 and parameters: {'alpha': 0.041656007753575044, 'l1_ratio': 0.3636937379329225}. Best is trial 12 with value: 0.163898912310572.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.430224145742283e-06, 'l1_ratio': 0.26693419316393463}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_coarse_study = optuna.create_study(direction='minimize')\n",
    "elasticnet_coarse_study.optimize(elasticnet_coarse_objective, n_trials=20)\n",
    "elasticnet_coarse_best_params = elasticnet_coarse_study.best_params\n",
    "elasticnet_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6 and l1 ratio 10^-1 to 10^0, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticnet_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.1, 1)\n",
    "    elasticnet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(elasticnet, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 09:23:34,290] A new study created in memory with name: no-name-4cba7b1c-2cca-4da3-af2e-fa5f5c067ab6\n",
      "[I 2024-02-10 09:26:20,845] Trial 0 finished with value: 0.16418770947259687 and parameters: {'alpha': 1.0611453153664617e-07, 'l1_ratio': 0.45916353635923446}. Best is trial 0 with value: 0.16418770947259687.\n",
      "[I 2024-02-10 09:28:53,523] Trial 1 finished with value: 0.16424038449077666 and parameters: {'alpha': 1.1420750225616437e-07, 'l1_ratio': 0.20522381933850875}. Best is trial 0 with value: 0.16418770947259687.\n",
      "[I 2024-02-10 09:31:25,821] Trial 2 finished with value: 0.164071997567935 and parameters: {'alpha': 2.2423122236687345e-07, 'l1_ratio': 0.7992642642371942}. Best is trial 2 with value: 0.164071997567935.\n",
      "[I 2024-02-10 09:34:30,205] Trial 3 finished with value: 0.163878654344104 and parameters: {'alpha': 2.7176833107958028e-06, 'l1_ratio': 0.8533991235497324}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:37:28,901] Trial 4 finished with value: 0.16403566654567386 and parameters: {'alpha': 3.8672324580177e-07, 'l1_ratio': 0.4779933638437509}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:40:14,404] Trial 5 finished with value: 0.16426449705444274 and parameters: {'alpha': 1.2352729671948035e-07, 'l1_ratio': 0.11864678826135235}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:43:20,331] Trial 6 finished with value: 0.16399453027677183 and parameters: {'alpha': 8.882144294199369e-07, 'l1_ratio': 0.26812969118131524}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:46:18,464] Trial 7 finished with value: 0.1639218301965095 and parameters: {'alpha': 1.3016987416790963e-06, 'l1_ratio': 0.8879587462092405}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:49:20,839] Trial 8 finished with value: 0.16414538449437077 and parameters: {'alpha': 1.3227615989421992e-07, 'l1_ratio': 0.6735551811223504}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:53:25,940] Trial 9 finished with value: 0.1639805050956207 and parameters: {'alpha': 6.212372021216146e-07, 'l1_ratio': 0.48379704172784355}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 09:56:51,463] Trial 10 finished with value: 0.16409438544538807 and parameters: {'alpha': 7.4853764761918e-06, 'l1_ratio': 0.980642817284316}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 10:00:03,432] Trial 11 finished with value: 0.163892051764027 and parameters: {'alpha': 2.6974131168859096e-06, 'l1_ratio': 0.9834199581022974}. Best is trial 3 with value: 0.163878654344104.\n",
      "[I 2024-02-10 10:03:38,787] Trial 12 finished with value: 0.16386670705706036 and parameters: {'alpha': 3.158809602865725e-06, 'l1_ratio': 0.7514172088257848}. Best is trial 12 with value: 0.16386670705706036.\n",
      "[I 2024-02-10 10:07:23,140] Trial 13 finished with value: 0.16385814266479345 and parameters: {'alpha': 3.857663967160253e-06, 'l1_ratio': 0.7066615186842985}. Best is trial 13 with value: 0.16385814266479345.\n",
      "[I 2024-02-10 10:10:46,173] Trial 14 finished with value: 0.1640450607697227 and parameters: {'alpha': 9.768596323596865e-06, 'l1_ratio': 0.6498272480615328}. Best is trial 13 with value: 0.16385814266479345.\n",
      "[I 2024-02-10 10:14:17,357] Trial 15 finished with value: 0.16385630151770753 and parameters: {'alpha': 3.943231695230683e-06, 'l1_ratio': 0.6838802956392738}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:18:30,114] Trial 16 finished with value: 0.16387238768157503 and parameters: {'alpha': 5.678956147492921e-06, 'l1_ratio': 0.6208721457218576}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:22:34,463] Trial 17 finished with value: 0.16391712987021884 and parameters: {'alpha': 1.5976337135550126e-06, 'l1_ratio': 0.38409142706861504}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:25:38,933] Trial 18 finished with value: 0.1638632877846918 and parameters: {'alpha': 4.121466072459011e-06, 'l1_ratio': 0.7361049942557509}. Best is trial 15 with value: 0.16385630151770753.\n",
      "[I 2024-02-10 10:28:20,014] Trial 19 finished with value: 0.16390116999106363 and parameters: {'alpha': 1.7092668821787898e-06, 'l1_ratio': 0.5798680598412542}. Best is trial 15 with value: 0.16385630151770753.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 3.943231695230683e-06, 'l1_ratio': 0.6838802956392738}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_fine_study = optuna.create_study(direction='minimize')\n",
    "elasticnet_fine_study.optimize(elasticnet_fine_objective, n_trials=20)\n",
    "elasticnet_fine_best_params = elasticnet_fine_study.best_params\n",
    "elasticnet_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 3.943231695230683e-06 and l1 ratio = 0.6838802956392738."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the elastic net model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fitted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sync\\03_projects\\data_science\\projects\\autoscout24-car-price-prediction\\envs\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.988e+01, tolerance: 1.813e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elasticnet_model = ElasticNet(alpha=elasticnet_fine_best_params['alpha'], l1_ratio=elasticnet_fine_best_params['l1_ratio'])\n",
    "elasticnet_start = datetime.now()\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "elasticnet_pred = elasticnet_model.predict(X_test)\n",
    "elasticnet_stop = datetime.now()\n",
    "elasticnet_delta = elasticnet_stop - elasticnet_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.948092</td>\n",
       "      <td>0.942306</td>\n",
       "      <td>4201.461942</td>\n",
       "      <td>77.137834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model        r2    r2_adj         rmse    seconds\n",
       "0  elasticnet  0.948092  0.942306  4201.461942  77.137834"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_pred_inverse = np.expm1(elasticnet_pred)\n",
    "\n",
    "elasticnet_r2 = r2_score(y_test, elasticnet_pred_inverse)\n",
    "elasticnet_r2_adj = 1 - (1 - elasticnet_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "elasticnet_rmse = np.sqrt(mean_squared_error(y_test, elasticnet_pred_inverse))\n",
    "elasticnet_seconds = elasticnet_delta.seconds + elasticnet_delta.microseconds/1E6\n",
    "\n",
    "elasticnet_evaluation = pd.DataFrame({\n",
    "    'model': ['elasticnet'],\n",
    "    'r2': [elasticnet_r2],\n",
    "    'r2_adj': [elasticnet_r2_adj],\n",
    "    'rmse': [elasticnet_rmse],\n",
    "    'seconds': [elasticnet_seconds]\n",
    "})\n",
    "\n",
    "elasticnet_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(elasticnet_model, '../models/models/elasticnet_model.pkl')\n",
    "elasticnet_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"elasticnet_evaluation.csv\"), index=False)\n",
    "elasticnet_res = pd.DataFrame(elasticnet_pred)\n",
    "elasticnet_res.index = X_test.index\n",
    "elasticnet_res.columns = [\"prediction\"]\n",
    "elasticnet_res.to_csv(\"../models/predictions/elasticnet_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Robust Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. Huber Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the huber regression hyperparameter optimization with an initial rough exploration of the hyperparameter space using Optuna's TPESampler algorithm (Tree-Structured Parzen Estimator), covering a wide range of values for the hyperparameters \"alpha\" and \"epsilon\". This preliminary search helps to identify a suitable range for subsequent fine-tuning within the optimal parameter space. A 5-fold cross-validation strategy is used to optimize computational efficiency, which ensures robust model evaluation while reducing the risk of overfitting. The Root Mean Squared Error (RMSE) is used as a performance evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_coarse_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-9, 1e9, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 1.0, 2.0)\n",
    "    huber = HuberRegressor(alpha=alpha, epsilon=epsilon)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(huber, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 15:47:23,505] A new study created in memory with name: no-name-47385cf4-8fe6-4b75-81f1-82d2eb27299f\n",
      "[I 2024-02-10 15:49:30,618] Trial 0 finished with value: 0.17015942234510364 and parameters: {'alpha': 0.2774699984085081, 'epsilon': 1.519249436181226}. Best is trial 0 with value: 0.17015942234510364.\n",
      "[I 2024-02-10 15:51:30,413] Trial 1 finished with value: 0.1714768544964337 and parameters: {'alpha': 9.775799499879854e-08, 'epsilon': 1.2290931912935026}. Best is trial 0 with value: 0.17015942234510364.\n",
      "[I 2024-02-10 15:53:41,531] Trial 2 finished with value: 0.16982439214150563 and parameters: {'alpha': 0.22676287042545554, 'epsilon': 1.8267688394701462}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 15:55:54,629] Trial 3 finished with value: 0.17027320860399597 and parameters: {'alpha': 3.1321014496836833e-07, 'epsilon': 1.7555549734712543}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 15:58:04,948] Trial 4 finished with value: 0.17030356318401868 and parameters: {'alpha': 0.0704131919475868, 'epsilon': 1.7391566886000884}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:00:12,451] Trial 5 finished with value: 0.170072255007298 and parameters: {'alpha': 0.0005541709414891476, 'epsilon': 1.7715477680346516}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:00:37,308] Trial 6 finished with value: 0.41733578260187204 and parameters: {'alpha': 7302.00797716347, 'epsilon': 1.2189539253408153}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:01:11,908] Trial 7 finished with value: 0.6816947301191714 and parameters: {'alpha': 337506.45712914603, 'epsilon': 1.9691412216114723}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:03:19,233] Trial 8 finished with value: 0.17039827167799793 and parameters: {'alpha': 0.010558255774634224, 'epsilon': 1.690776817406741}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:05:41,304] Trial 9 finished with value: 0.17157736313297617 and parameters: {'alpha': 20.979477252849264, 'epsilon': 1.5151379559337288}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:06:14,408] Trial 10 finished with value: 0.7108211117995801 and parameters: {'alpha': 683395070.673746, 'epsilon': 1.0061645545302738}. Best is trial 2 with value: 0.16982439214150563.\n",
      "[I 2024-02-10 16:08:25,569] Trial 11 finished with value: 0.16923431638158884 and parameters: {'alpha': 7.37950301489792e-05, 'epsilon': 1.9886807708950724}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:10:39,016] Trial 12 finished with value: 0.1694651918829237 and parameters: {'alpha': 2.9211412984681153e-05, 'epsilon': 1.9943181087027557}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:12:47,224] Trial 13 finished with value: 0.16943434411739558 and parameters: {'alpha': 1.0530757080550188e-09, 'epsilon': 1.9885557423760372}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:14:57,079] Trial 14 finished with value: 0.16971687087997073 and parameters: {'alpha': 1.7222302802036026e-09, 'epsilon': 1.9105705777410327}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:17:04,741] Trial 15 finished with value: 0.17000930310591286 and parameters: {'alpha': 1.1074523598280377e-09, 'epsilon': 1.6308953092133633}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:19:12,257] Trial 16 finished with value: 0.1695399944885847 and parameters: {'alpha': 1.3024131082866523e-05, 'epsilon': 1.88608724758239}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:21:12,544] Trial 17 finished with value: 0.17160200795982386 and parameters: {'alpha': 3.691044973705169e-07, 'epsilon': 1.3081358195483577}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:23:16,865] Trial 18 finished with value: 0.17012204089796898 and parameters: {'alpha': 2.8063941907652296e-05, 'epsilon': 1.609421672092024}. Best is trial 11 with value: 0.16923431638158884.\n",
      "[I 2024-02-10 16:25:22,321] Trial 19 finished with value: 0.17018304909094353 and parameters: {'alpha': 2.8198455011986057e-08, 'epsilon': 1.8606944339747558}. Best is trial 11 with value: 0.16923431638158884.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 7.37950301489792e-05, 'epsilon': 1.9886807708950724}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_coarse_study = optuna.create_study(direction='minimize')\n",
    "huber_coarse_study.optimize(huber_coarse_objective, n_trials=20)\n",
    "huber_coarse_best_params = huber_coarse_study.best_params\n",
    "huber_coarse_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest test scores were achieved within the alpha range of 10^-6 and epsilon near 2, therefore, proceed with hyperparameter optimization, emphasizing this optimal parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fine_objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-7, 1e-5, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 1.9, 2.0)\n",
    "    huber = HuberRegressor(alpha=alpha, epsilon=epsilon)\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = cross_val_score(huber, X_train, y_train, scoring='neg_root_mean_squared_error', cv=kfolds, n_jobs=-1)\n",
    "    return -rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-10 14:25:45,437] A new study created in memory with name: no-name-277db13d-15d2-452b-91f4-05b591138b2a\n",
      "[I 2024-02-10 14:28:23,261] Trial 0 finished with value: 0.16946093642638044 and parameters: {'alpha': 2.102586098773178e-07, 'epsilon': 1.9317520120367464}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:30:28,051] Trial 1 finished with value: 0.16974317582031384 and parameters: {'alpha': 1.9436391916273176e-07, 'epsilon': 1.9107556093185707}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:32:34,315] Trial 2 finished with value: 0.16953010917304015 and parameters: {'alpha': 2.301815405272179e-06, 'epsilon': 1.905033163742058}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:34:33,496] Trial 3 finished with value: 0.16966976655452734 and parameters: {'alpha': 3.356769436674778e-06, 'epsilon': 1.9473879754958292}. Best is trial 0 with value: 0.16946093642638044.\n",
      "[I 2024-02-10 14:36:35,010] Trial 4 finished with value: 0.16922765585564442 and parameters: {'alpha': 3.7073096832852122e-06, 'epsilon': 1.9540079080431}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:38:35,826] Trial 5 finished with value: 0.16942797901372325 and parameters: {'alpha': 9.330137945313375e-07, 'epsilon': 1.955646440724383}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:40:36,199] Trial 6 finished with value: 0.16939158131355123 and parameters: {'alpha': 6.865079761948513e-07, 'epsilon': 1.9773210184585013}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:42:37,046] Trial 7 finished with value: 0.16941457665618806 and parameters: {'alpha': 4.574028083149486e-06, 'epsilon': 1.940037621821646}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:44:38,882] Trial 8 finished with value: 0.16933531921949987 and parameters: {'alpha': 1.2720554262357714e-06, 'epsilon': 1.9487695954769726}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:46:38,966] Trial 9 finished with value: 0.16957630074956415 and parameters: {'alpha': 3.7236099422569674e-06, 'epsilon': 1.980517614085017}. Best is trial 4 with value: 0.16922765585564442.\n",
      "[I 2024-02-10 14:48:40,870] Trial 10 finished with value: 0.16921927225422212 and parameters: {'alpha': 8.627070834562276e-06, 'epsilon': 1.995917458517765}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:50:38,808] Trial 11 finished with value: 0.16938796828763142 and parameters: {'alpha': 9.136854435750553e-06, 'epsilon': 1.9963534795415259}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:52:38,858] Trial 12 finished with value: 0.16967737518259907 and parameters: {'alpha': 7.886152988440147e-06, 'epsilon': 1.9995070689878087}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:54:54,958] Trial 13 finished with value: 0.16949166396223964 and parameters: {'alpha': 1.6925231173086753e-06, 'epsilon': 1.9664403768546874}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:57:06,718] Trial 14 finished with value: 0.1695112070302357 and parameters: {'alpha': 4.4691130309461986e-07, 'epsilon': 1.9201119001686593}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 14:59:12,961] Trial 15 finished with value: 0.16979681353803583 and parameters: {'alpha': 6.844892803877861e-06, 'epsilon': 1.9808512282372495}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:01:21,913] Trial 16 finished with value: 0.16969843302940663 and parameters: {'alpha': 5.019823754025895e-06, 'epsilon': 1.964156609143939}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:03:42,789] Trial 17 finished with value: 0.16963643421171734 and parameters: {'alpha': 2.520001250750877e-06, 'epsilon': 1.9266957765677928}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:05:52,335] Trial 18 finished with value: 0.1692286120387035 and parameters: {'alpha': 9.104614933675814e-06, 'epsilon': 1.986616205097269}. Best is trial 10 with value: 0.16921927225422212.\n",
      "[I 2024-02-10 15:07:57,811] Trial 19 finished with value: 0.16962897613266864 and parameters: {'alpha': 5.509361416140461e-06, 'epsilon': 1.9659346578804895}. Best is trial 10 with value: 0.16921927225422212.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 8.627070834562276e-06, 'epsilon': 1.995917458517765}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_fine_study = optuna.create_study(direction='minimize')\n",
    "huber_fine_study.optimize(huber_fine_objective, n_trials=20)\n",
    "huber_fine_best_params = huber_fine_study.best_params\n",
    "huber_fine_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 8.627070834562276e-06, 'epsilon': 1.995917458517765}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_fine_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is minimized at alpha = 8.627070834562276e-06 and epsilon = 1.995917458517765."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Huber regression model using the optimal hyperparameters, generate predictions for the test data using this trained model, evaluate the prediction performance, and display the results in a DataFrame. Additionally, save the fit-ted model as a pickle file, the model evaluation table, and the predictions as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber_model = HuberRegressor(alpha=huber_fine_best_params['alpha'], epsilon=huber_fine_best_params['epsilon'], max_iter=10000)\n",
    "huber_start = datetime.now()\n",
    "huber_model.fit(X_train, y_train.values.ravel())\n",
    "huber_pred = huber_model.predict(X_test)\n",
    "huber_stop = datetime.now()\n",
    "huber_delta = huber_stop - huber_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_adj</th>\n",
       "      <th>rmse</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huber</td>\n",
       "      <td>0.950388</td>\n",
       "      <td>0.944858</td>\n",
       "      <td>4107.468443</td>\n",
       "      <td>1056.937912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        r2    r2_adj         rmse      seconds\n",
       "0  huber  0.950388  0.944858  4107.468443  1056.937912"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_pred_inverse = np.expm1(huber_pred)\n",
    "\n",
    "huber_r2 = r2_score(y_test, huber_pred_inverse)\n",
    "huber_r2_adj = 1 - (1 - huber_r2) * ((len(X_test) - 1) / (len(X_test) - len(X_test.columns) - 1))\n",
    "huber_rmse = np.sqrt(mean_squared_error(y_test, huber_pred_inverse))\n",
    "huber_seconds = huber_delta.seconds + huber_delta.microseconds/1E6\n",
    "\n",
    "huber_evaluation = pd.DataFrame({\n",
    "    'model': ['huber'],\n",
    "    'r2': [huber_r2],\n",
    "    'r2_adj': [huber_r2_adj],\n",
    "    'rmse': [huber_rmse],\n",
    "    'seconds': [huber_seconds]\n",
    "})\n",
    "\n",
    "huber_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(huber_model, '../models/models/huber_model.pkl')\n",
    "huber_evaluation.to_csv(os.path.join(\"../models/evaluation/\", \"huber_evaluation.csv\"), index=False)\n",
    "huber_res = pd.DataFrame(huber_pred)\n",
    "huber_res.index = X_test.index\n",
    "huber_res.columns = [\"prediction\"]\n",
    "huber_res.to_csv(\"../models/predictions/huber_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3. RANSAC Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4. Theil Sen Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1. Multi-Layer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Decision Trees Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.1. Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.2. Bagging Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.3. Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.4. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.6. LightGBM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.7. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.8. Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.9. Stacking Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.10. Voting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.11. Histogram-based Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Dimensionality-Reduced Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Bayesian Linear Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
